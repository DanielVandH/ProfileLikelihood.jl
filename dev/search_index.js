var documenterSearchIndex = {"docs":
[{"location":"regression/#Example-I:-Multiple-linear-regression","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"","category":"section"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"Let us start with a linear regression example. First, load the packages needed:","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using ProfileLikelihood\nusing Random \nusing PreallocationTools \nusing Distributions \nusing CairoMakie \nusing LaTeXStrings \nusing LinearAlgebra\nusing Optimization \nusing OptimizationOptimJL","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We perform a simulation study where we try and estimate the parameters in a regression of the form ","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"y_i = beta_0 + beta_1x_1i + beta_2x_2i + beta_3x_1ix_3i + varepsilon_i quad varepsilon_i sim mathcal N(0 sigma^2) quad i=12ldots n ","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We also try and estimate sigma. ","category":"page"},{"location":"regression/#Setting-up-the-problem","page":"Example I: Multiple linear regression","title":"Setting up the problem","text":"","category":"section"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"Let us start by simulating the data:","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using Random, Distributions \nRandom.seed!(98871)\nn = 600\nβ = [-1.0, 1.0, 0.5, 3.0]\nσ = 0.05\nx₁ = rand(Uniform(-1, 1), n)\nx₂ = rand(Normal(1.0, 0.5), n)\nX = hcat(ones(n), x₁, x₂, x₁ .* x₂)\nε = rand(Normal(0.0, σ), n)\ny = X * β + ε","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"The data y is now our noisy data. The likelihood function in this example is ","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"ell(sigma boldsymbol beta mid boldsymbol y) = -(n2)log(2mathrmpisigma^2) - (12sigma^2)sum_i (y_i - beta_0 - beta_1x_1i - beta_2x_2i - beta_3x_1ix_2i)^2 ","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We now define our likelihood function. To allow for automatic differentiation, we use PreallocationTools.DiffCache to define our cache vectors.","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"sse = DiffCache(zeros(n))\nβ_cache = DiffCache(similar(β), 10)\ndat = (y, X, sse, n, β_cache)\n@inline function loglik_fnc(θ, data)\n    σ, β₀, β₁, β₂, β₃ = θ\n    y, X, sse, n, β = data\n    _sse = get_tmp(sse, θ)\n    _β = get_tmp(β, θ)\n    _β[1] = β₀\n    _β[2] = β₁\n    _β[3] = β₂\n    _β[4] = β₃\n    ℓℓ = -0.5n * log(2π * σ^2)\n    mul!(_sse, X, _β)\n    for i in eachindex(y)\n        ℓℓ = ℓℓ - 0.5 / σ^2 * (y[i] - _sse[i])^2\n    end\n    return ℓℓ\nend","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"Now having defined our likelihood, we can define the likelihood problem. We let the problem be unconstrained, except for sigma  0. We start at the value 1 for each parameter. To use automatic differentiation, we use Optimization.AutoForwardDiff for the adtype.","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using Optimization, ForwardDiff\nθ₀ = ones(5)\nprob = LikelihoodProblem(loglik_fnc, θ₀;\n    data=dat,\n    f_kwargs=(adtype=Optimization.AutoForwardDiff(),),\n    prob_kwargs=(\n        lb=[0.0, -Inf, -Inf, -Inf, -Inf],\n        ub=Inf * ones(5)\n    ),\n    syms=[:σ, :β₀, :β₁, :β₂, :β₃]\n)\nLikelihoodProblem. In-place: true\nθ₀: 5-element Vector{Float64}\n     σ: 1.0\n     β₀: 1.0\n     β₁: 1.0\n     β₂: 1.0\n     β₃: 1.0","category":"page"},{"location":"regression/#Finding-the-MLEs","page":"Example I: Multiple linear regression","title":"Finding the MLEs","text":"","category":"section"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"Now we can compute the MLEs.","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using OptimizationOptimJL\nsol = mle(prob, Optim.LBFGS())\nLikelihoodSolution. retcode: Success\nMaximum likelihood: 957.6376683220673\nMaximum likelihood estimates: 5-element Vector{Float64}\n     σ: 0.049045771053511954\n     β₀: -1.0041730424101303\n     β₁: 1.006051999753723\n     β₂: 0.5041343138021581\n     β₃: 2.9922041467801934","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We can compare these MLEs to the true MLES hatbeta = (boldsymbol X^mathsf Tboldsymbol X)^-1boldsymbol X^mathsf Tboldsymbol y and hatsigma^2 = (1n_d)(boldsymbol y - boldsymbol Xboldsymbol beta)^mathsf T(boldsymbol y - boldsymbol Xboldsymbol beta), where n_d is the degrees of freedom, as follows (note the indexing):","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using Test, LinearAlgebra\ndf = n - (length(β) + 1)\nresids = y .- X * sol[2:5]\n@test sol[2:5] ≈ inv(X' * X) * X' * y # sol[i] = sol.mle[i] \n@test sol[:σ]^2 ≈ 1 / df * sum(resids .^ 2) atol = 1e-4 # symbol indexing","category":"page"},{"location":"regression/#Profiling","page":"Example I: Multiple linear regression","title":"Profiling","text":"","category":"section"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We can now profile the results. In this case, since the problem has no bounds for some parameters we need to manually define the parameter bounds used for profiling. The function construct_profile_ranges is used for this. Note that we use parallel = true below to allow for multithreading, allowing multiple parameters to be profiled at the same time.","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"lb = [1e-12, -5.0, -5.0, -5.0, -5.0]\nub = [15.0, 15.0, 15.0, 15.0, 15.0]\nresolutions = [600, 200, 200, 200, 200] # use many points for σ\nparam_ranges = construct_profile_ranges(sol, lb, ub, resolutions)\nprof = profile(prob, sol; param_ranges, parallel=true)\nProfileLikelihoodSolution. MLE retcode: Success\nConfidence intervals: \n     95.0% CI for σ: (0.04639652142575396, 0.05196200098682017)\n     95.0% CI for β₀: (-1.013328678265197, -0.9950163004240635)\n     95.0% CI for β₁: (0.9906172772152076, 1.0214865014037124)\n     95.0% CI for β₂: (0.4960199617761395, 0.5122490969333844)\n     95.0% CI for β₃: (2.978618197988093, 3.0057902255444136)","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"These confidence intervals can be compared to the true confidence intervals as follows, noting that the variance-covariance matrix for the beta_i coefficients is boldsymbolSigma = sigma^2(boldsymbol X^mathsf Tboldsymbol X)^-1 so that their confidence interval is hatbeta_i pm 196sqrtboldsymbolSigma_ii. Additionally, a confidence interval for sigma is sqrt(boldsymbol y - boldsymbol Xboldsymbol beta)^mathsf T(boldsymbol y - boldsymbol Xboldsymbol beta)(1sqrtchi_0975 n_d 1sqrtchi_0025 n_d).","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"vcov_mat = sol[:σ]^2 * inv(X' * X)\nfor i in 1:4\n    @test prof.confidence_intervals[i+1][1] ≈ sol.mle[i+1] - 1.96sqrt(vcov_mat[i, i]) atol = 1e-3\n    @test prof.confidence_intervals[i+1][2] ≈ sol.mle[i+1] + 1.96sqrt(vcov_mat[i, i]) atol = 1e-3\nend\nrss = sum(resids .^ 2)\nχ²_up = quantile(Chisq(df), 0.975)\nχ²_lo = quantile(Chisq(df), 0.025)\nσ_CI_exact = sqrt.(rss ./ (χ²_up, χ²_lo))\n@test get_confidence_intervals(prof, :σ).lower ≈ σ_CI_exact[1] atol = 1e-3\n@test ProfileLikelihood.get_upper(get_confidence_intervals(prof, :σ)) ≈ σ_CI_exact[2] atol = 1e-3","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"You can use prof to view a single parameter's results, e.g.","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"prof[:β₂]\nProfile likelihood for parameter β₂. MLE retcode: Success\nMLE: 0.5041343138021581\n95.0% CI for β₂: (0.4960199617761438, 0.5122490969333844)","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"You can also evaluate the profile at a point inside its confidence interval. (If you want to evaluate outside the confidence interval, you need to use a non-Throw extrap in the profile function's keyword argument [see also Interpolations.jl].) The following are all the same, evaluating the profile for beta_2 at beta_2=05:","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"prof[:β₂](0.50)\nprof(0.50, :β₂)\nprof(0.50, 4)","category":"page"},{"location":"regression/#Visualisation","page":"Example I: Multiple linear regression","title":"Visualisation","text":"","category":"section"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"We can now also visualise the results. In the plot below, the red line is at the threshold for the confidence region, so that the parameters between these values define the confidence interval. The red lines are at the MLEs, and the black lines are at the true values. ","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"using CairoMakie, LaTeXStrings\nfig = plot_profiles(prof;\n    latex_names=[L\"\\sigma\", L\"\\beta_0\", L\"\\beta_1\", L\"\\beta_2\", L\"\\beta_3\"], # default names would be of the form θᵢ\n    show_mles=true,\n    shade_ci=true,\n    true_vals=[σ, β...],\n    fig_kwargs=(fontsize=30, resolution=(2134.0f0, 906.0f0)),\n    axis_kwargs=(width=600, height=300))\nxlims!(fig.content[1], 0.045, 0.055) # fix the ranges\nxlims!(fig.content[2], -1.025, -0.975)\nxlims!(fig.content[4], 0.475, 0.525)","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"(Image: Regression profiles)","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"You could also plot individual or specific parameters:","category":"page"},{"location":"regression/","page":"Example I: Multiple linear regression","title":"Example I: Multiple linear regression","text":"plot_profiles(prof, [1, 3]) # plot σ and β₁\nplot_profiles(prof, [:σ, :β₁, :β₃]) # can use symbols \nplot_profiles(prof, 1) # can just provide an integer \nplot_profiles(prof, :β₂) # symbols work","category":"page"},{"location":"heat/#Example-IV:-Diffusion-equation-on-a-square-plate","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Warning: Much of the code in this example takes a very long time, e.g. the MLEs take just under an hour. The total runtime is around six hours on my machine (mostly coming from the mesh for the PDE being very dense). ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The packages we use in this example are:","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"using FiniteVolumeMethod \nusing ProfileLikelihood \nusing DelaunayTriangulation\nusing Random \nusing LinearSolve \nusing OrdinaryDiffEq\nusing CairoMakie \nusing LaTeXStrings\nusing StaticArraysCore\nusing Optimization \nusing OptimizationNLopt","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us now consider the problem of estimating parameters defining a diffusion equation on a square plate. In particular, consider ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"beginequation*\nbeginarrayrcll\ndisplaystyle\nfracpartial u(x y t)partial t = dfrac1kboldsymbolnabla^2 u(x y t)  (x y) in Omegat0 \nu(x y t) =  0  (x y) in partial Omegat0 \nu(x y 0) =  u_0mathbbI(y leq c) (xy)inOmega\nendarray\nendequation*","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"where Omega = 0 2^2. This problem extends the corresponding example given in FiniteVolumeMethod.jl, namely this example, and so not all the code used in defining this PDE will be explained here; refer to the FiniteVolumeMethod.jl documentation. We will take the true values k = 9, c = 1, u_0 = 50, and let the standard deviation of the noise, sigma, in the data be 01. We are interested in recovering (k c u_0); we do not consider estimating sigma here, estimating it leads to identifiability issues that distract from the main point of our example here, i.e. to just show how to setup a problem.","category":"page"},{"location":"heat/#Building-the-FVMProblem","page":"Example IV: Diffusion equation on a square plate","title":"Building the FVMProblem","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us start by defining the PDE problem, and then we will discuss profiling.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"using FiniteVolumeMethod, DelaunayTriangulation, LinearSolve\na, b, c, d = 0.0, 2.0, 0.0, 2.0\nn = 500\nx₁ = LinRange(a, b, n)\nx₂ = LinRange(b, b, n)\nx₃ = LinRange(b, a, n)\nx₄ = LinRange(a, a, n)\ny₁ = LinRange(c, c, n)\ny₂ = LinRange(c, d, n)\ny₃ = LinRange(d, d, n)\ny₄ = LinRange(d, c, n)\nx = reduce(vcat, [x₁, x₂, x₃, x₄])\ny = reduce(vcat, [y₁, y₂, y₃, y₄])\nxy = [[x[i], y[i]] for i in eachindex(x)]\nunique!(xy)\nx = getx.(xy)\ny = gety.(xy)\nr = 0.022\nGMSH_PATH = \"./gmsh-4.9.4-Windows64/gmsh.exe\"\nT, adj, adj2v, DG, points, BN = generate_mesh(x, y, r; gmsh_path=GMSH_PATH)\nmesh = FVMGeometry(T, adj, adj2v, DG, points, BN)\nbc = ((x, y, t, u::T, p) where {T}) -> zero(T)\ntype = :D\nBCs = BoundaryConditions(mesh, bc, type, BN)\nc = 1.0\nu₀ = 50.0\nf = (x, y) -> y ≤ c ? u₀ : 0.0\nD = (x, y, t, u, p) -> p[1]\nflux = (q, x, y, t, α, β, γ, p) -> (q[1] = -α / p[1]; q[2] = -β / p[1])\nR = ((x, y, t, u::T, p) where {T}) -> zero(T)\ninitc = @views f.(points[1, :], points[2, :])\niip_flux = true\nfinal_time = 0.1\nk = [9.0]\nprob = FVMProblem(mesh, BCs; iip_flux,\n    flux_function=flux, reaction_function=R,\n    initial_condition=initc, final_time,\n    flux_parameters=k)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Our problem has now been defined. Notice that we wrap k in a vector so that we can easily mutate the flux_parameters field of prob; if k were a scalar, we could not mutate it.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now let's generate some data. We start by solving the PDE.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"alg = TRBDF2(linsolve=KLUFactorization(; reuse_symbolic=false))\nsol = solve(prob, alg; specialization=SciMLBase.FullSpecialize, saveat=0.01)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"(We use reuse_symbolic=false due to https://github.com/JuliaSparse/KLU.jl/issues/12 causing issues with multithreading later.) ","category":"page"},{"location":"heat/#Defining-a-summary-statistic","page":"Example IV: Diffusion equation on a square plate","title":"Defining a summary statistic","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now, one complication with a PDE compared to the scalar ODE cases that we considered previously is that we have data at (x_i y_j t_k) for many indices (i j k). Rather than defining our objective function in terms of these data points, we will instead use a summary statistic. The summary statistic we use in this example is the average density,","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"tilde M(t) = frac1mathrmArea(Omega)iint_Omega u(x y t)mathrmdA ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"We need to be able to compute this integral efficiently and accurately. For this, recall that the finite volume method discretises the domain into triangles. If mathcal T is this set of triangles, then ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"tilde M(t) = frac1mathrmArea(Omega)sum_T_k in mathcal T iint_T_k u(x y t)mathrmdA ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Then, recall that u is represented as a linear function alpha_k x + beta_k y + gamma_k inside the triangle T_k, thus ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"tilde M(t) approx frac1mathrmArea(Omega)sum_T_k in mathcal T leftalpha_k iint_T_k xmathrmdA + beta_k iint_T_k ymathrmdA + gamma_kiint_T_kmathrmdAright ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now factoring out an mathrmArea(T_k) = iint_T_kmathrmdA, ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"tilde M(t) approx sum_T_k in mathcal T fracmathrmArea(T_k)mathrmArea(Omega)leftalpha_k dfraciint_T_k xmathrmdAiint_T_k mathrmdA + beta_k dfraciint_T_k ymathrmdAiint_T_k mathrmdA + gamma_kright ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Notice that the two ratios of integrals shown are simply hat x_k and hat y_k, where (hat x_k hat y_k) is the centroid of T_k. Thus, the term in brackets is alpha_k hat x_k + beta_k hat y_k + gamma_k, which is the approximation to u at the centroid, tilde u(hat x_k hat y_k t). Thus, our approximation to the average density is ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"tilde M(t) approx sum_T_k in mathcal T w_k tilde u(hat x_k hat y_k t) qquad w_k = fracmathrmArea(T_k)mathrmArea(Omega) ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The following function provides a method for computing this mass. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"function compute_mass!(M::AbstractVector{T}, αβγ, sol, prob) where {T}\n    mesh_area = prob.mesh.mesh_information.total_area\n    fill!(M, zero(T))\n    for i in eachindex(M)\n        for V in FiniteVolumeMethod.get_elements(prob)\n            element = FiniteVolumeMethod.get_element_information(prob.mesh, V)\n            cx, cy = FiniteVolumeMethod.get_centroid(element)\n            element_area = FiniteVolumeMethod.get_area(element)\n            interpolant_val = eval_interpolant!(αβγ, prob, cx, cy, V, sol.u[i])\n            M[i] += (element_area / mesh_area) * interpolant_val\n        end\n    end\n    return nothing\nend ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let's now compute this mass and add some noise onto it. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"using Random \nM = zeros(length(sol.t))\nαβγ = zeros(3)\ncompute_mass!(M, αβγ, sol, prob)\ntrue_M = deepcopy(M)\nRandom.seed!(29922881)\nσ = 0.1\ntrue_M .+= σ * randn(length(M))","category":"page"},{"location":"heat/#Defining-the-LikelihoodProblem","page":"Example IV: Diffusion equation on a square plate","title":"Defining the LikelihoodProblem","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"We now need to define the likelihood problem. We need to use the method for LikelihoodProblem that takes the integrator as an argument explicitly, so we must somehow construct an integrator from an FVMProblem. Here is one way that this can be done. Notice that we use parallel=true so that the PDE is solved with multithreading. For an isolated solution, this seems to solve the PDE twice as fast on my machine (eight threads).","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"function ProfileLikelihood.construct_integrator(prob::FVMProblem, alg; ode_problem_kwargs, kwargs...)\n    ode_problem = ODEProblem(prob; no_saveat=false, ode_problem_kwargs...)\n    return ProfileLikelihood.construct_integrator(ode_problem, alg; kwargs...)\nend\njac = float.(FiniteVolumeMethod.jacobian_sparsity(prob))\nfvm_integrator = construct_integrator(prob, alg; ode_problem_kwargs=(jac_prototype=jac, saveat=0.01, parallel=true))","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now we define the likelihood function. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"function loglik_fvm(θ::AbstractVector{T}, param, integrator) where {T}\n    _k, _c, _u₀ = θ\n    ## Update and solve\n    (; prob) = param\n    prob.flux_parameters[1] = _k\n    pts = FiniteVolumeMethod.get_points(prob)\n    for i in axes(pts, 2)\n        pt = get_point(pts, i)\n        prob.initial_condition[i] = gety(pt) ≤ _c ? _u₀ : zero(T)\n    end\n    reinit!(integrator, prob.initial_condition)\n    solve!(integrator)\n    if !SciMLBase.successful_retcode(integrator.sol)\n        return typemin(T)\n    end\n    ## Compute the mass\n    (; mass_data, mass_cache, shape_cache, sigma) = param\n    compute_mass!(mass_cache, shape_cache, integrator.sol, prob)\n    if any(isnan, mass_cache)\n        return typemin(T)\n    end\n    ## Done \n    ℓ = @views gaussian_loglikelihood(mass_data, mass_cache, sigma, length(mass_data))\n    return ℓ\nend","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Finally, here is the LikelihoodProblem.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"likprob = LikelihoodProblem(\n    loglik_fvm,\n    [8.54, 0.98, 29.83],\n    fvm_integrator;\n    syms=[:k, :c, :u₀],\n    data=(prob=prob, mass_data=true_M, mass_cache=zeros(length(true_M)), shape_cache=zeros(3), sigma=σ),\n    f_kwargs=(adtype=Optimization.AutoFiniteDiff(),),\n    prob_kwargs=(lb=[3.0, 0.0, 0.0],\n        ub=[15.0, 2.0, 250.0])\n)","category":"page"},{"location":"heat/#Parameter-estimation","page":"Example IV: Diffusion equation on a square plate","title":"Parameter estimation","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now that we have the problem completely setup, we are in a position for maximum likelihood estimation and profiling. For the maximum likelihood estimates, we first use a global optimiser and then we refine the solution with a local optimiser.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"mle_sol = mle(likprob, (NLopt.GN_DIRECT_L_RAND(), NLopt.LN_BOBYQA); ftol_abs=1e-8, ftol_rel=1e-8, xtol_abs=1e-8, xtol_rel=1e-8) # global, and then refine with a local algorithm\nLikelihoodSolution. retcode: Failure\nMaximum likelihood: 11.046014040624534\nMaximum likelihood estimates: 3-element Vector{Float64}\n     k: 7.847020395441574\n     c: 1.1944331289720689\n     u₀: 41.667309553688305","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Next, let us profile. For interest, we show the difference in runtime when we use multithreading for profiling vs. when we do not use multithreading. I am using eight threads.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"@time prof = profile(likprob, mle_sol; alg=NLopt.LN_BOBYQA,\n    ftol_abs=1e-4, ftol_rel=1e-4, xtol_abs=1e-4, xtol_rel=1e-4,\n    resolution=60)\n5131.960778 seconds (133.61 M allocations: 948.495 GiB, 0.13% gc time, 0.04% compilation time)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"@time _prof = profile(likprob, mle_sol; alg=NLopt.LN_BOBYQA,\n    ftol_abs=1e-4, ftol_rel=1e-4, xtol_abs=1e-4, xtol_rel=1e-4,\n    resolution=60, parallel=true)\n3324.605865 seconds (131.24 M allocations: 948.598 GiB, 0.40% gc time, 0.01% compilation time)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The results are about twice as fast in this example. The reason it's not even faster is because we are also using multithreading in solving the PDE. If we had no used multithreading in solving the PDE, these results would take a significantly longer time. Here are the results from prof (same for _prof):","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"ProfileLikelihoodSolution. MLE retcode: Failure\nConfidence intervals: \n     95.0% CI for k: (7.4088716591304715, 8.574442050142432)\n     95.0% CI for c: (0.6478281377475628, 2.0)\n     95.0% CI for u₀: (33.78499567791489, 79.47955668442242)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"See that all the true parameter intervals are inside these confidence intervals except for k, although c's upper bound is right at the bounds we gave it in the problem. Let's now view the profile curves.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"using CairoMakie, LaTeXStrings\nfig = plot_profiles(prof; nrow=1, ncol=3,\n    latex_names=[L\"k\", L\"c\", L\"u_0\"],\n    true_vals=[k[1], c, u₀],\n    fig_kwargs=(fontsize=38, resolution=(2109.644f0, 444.242f0)),\n    axis_kwargs=(width=600, height=300))\nscatter!(fig.content[1], get_parameter_values(prof, :k), get_profile_values(prof, :k), color=:black, markersize=9)\nscatter!(fig.content[2], get_parameter_values(prof, :c), get_profile_values(prof, :c), color=:black, markersize=9)\nscatter!(fig.content[3], get_parameter_values(prof, :u₀), get_profile_values(prof, :u₀), color=:black, markersize=9)\nxlims!(fig.content[1], 7.0, 9.5)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"(Image: PDE profiles)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"See that the profile curves for c and u_0 are very flat, and we have not recovered k. This means that the parameters c and u_0 are not identifiable, essentially meaning the data is not enough to recover these parameters. This is most likely because the mass tilde M(t) alone is not enough to uniquely define the solution. We could consider a summary statistic like ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"mathcal S(t) = wtilde M(t) + (1-w)tilde A(t)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"for some 0 leq w leq 1, where tilde A(t) is the area of the region below the leading edge of the solution, i.e. the area of the non-zero part of the solution. We do not consider this here. What we do consider is fixing c, keeping the summary statistic tilde M(t), and seeing what we can do with only two parameters k and u_0.","category":"page"},{"location":"heat/#Reducing-to-two-parameters-and-grid-searching","page":"Example IV: Diffusion equation on a square plate","title":"Reducing to two parameters and grid searching","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us now fix c at its true value, c = 1, and consider estimating only k and u_0. Since we have only k and u_0 to estimate, it may be worthwhile to perform a grid search over our likelihood function so that we can (1) visualise the likelihood surface and (2) see reasonable estimates for k and u_0. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"First, we redefine the problem.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"using StaticArraysCore\n@inline function loglik_fvm_2(θ::AbstractVector{T}, param, integrator) where {T}\n    _k, _u₀, = θ\n    (; c) = param\n    new_θ = SVector{3,T}((_k, c, _u₀))\n    return loglik_fvm(new_θ, param, integrator)\n\nend\nlikprob_2 = LikelihoodProblem(\n    loglik_fvm_2,\n    [8.54, 29.83],\n    fvm_integrator;\n    syms=[:k, :u₀],\n    data=(prob=prob, mass_data=true_M, mass_cache=zeros(length(true_M)), shape_cache=zeros(3), sigma=σ, c=c),\n    f_kwargs=(adtype=Optimization.AutoFiniteDiff(),),\n    prob_kwargs=(lb=[3.0, 0.0],\n        ub=[15.0, 250.0])\n)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now let's do our grid search. We show the timing when we use a multithreaded grid search vs. a serial grid search. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"grid = RegularGrid(get_lower_bounds(likprob_2), get_upper_bounds(likprob_2), 50)\n@time gs, lik_vals = grid_search(likprob_2, grid; save_vals = Val(true), parallel=Val(true))\n1529.393520 seconds (91.55 M allocations: 606.223 GiB, 2.10% gc time)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"@time _gs, _lik_vals = grid_search(likprob_2, grid; save_vals = Val(true), parallel=Val(false))\n3454.357503 seconds (86.48 M allocations: 605.468 GiB, 0.14% gc time)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Here are the results from the grid search.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"LikelihoodSolution. retcode: Success\nMaximum likelihood: -24.399451875029165\nMaximum likelihood estimates: 2-element Vector{Float64}\n     k: 7.408163265306122\n     u₀: 51.0204081632653","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us now visualise the likelihood function.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"fig = Figure(fontsize=38)\nk_grid = get_range(grid, 1)\nu₀_grid = get_range(grid, 2)\nax = Axis(fig[1, 1],\n    xlabel=L\"k\", ylabel=L\"u_0\",\n    xticks=0:3:15,\n    yticks=0:50:250)\nco = heatmap!(ax, k_grid, u₀_grid, lik_vals, colormap=Reverse(:matter))\ncontour!(ax, k_grid, u₀_grid, lik_vals, levels=40, color=:black, linewidth=1 / 4)\nscatter!(ax, [k[1]], [u₀], color=:white, markersize=14)\nscatter!(ax, [gs[:k]], [gs[:u₀]], color=:blue, markersize=14)\nclb = Colorbar(fig[1, 2], co, label=L\"\\ell(k, u_0)\", vertical=true)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"(Image: Likelihood function for the PDE)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The true parameter values are shown at the white marker, while the results from the grid search are shown in blue, and these two markers are reasonably close. We see that the likelihood function is quite flat around these values, so this might be an indicator of further identifiability issues. Let us now use the grid search results to update our initial guess and compute the MLEs, and then we profile.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"likprob_2 = update_initial_estimate(likprob_2, gs)\nmle_sol = mle(likprob_2, NLopt.LN_BOBYQA; ftol_abs=1e-8, ftol_rel=1e-8, xtol_abs=1e-8, xtol_rel=1e-8)\nLikelihoodSolution. retcode: Failure\nMaximum likelihood: 11.016184577792082\nMaximum likelihood estimates: 2-element Vector{Float64}\n     k: 9.40527352240195\n     u₀: 49.741093700294336","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"@time prof = profile(likprob_2, mle_sol; ftol_abs=1e-4, ftol_rel=1e-4, xtol_abs=1e-4, xtol_rel=1e-4, parallel=true)\n612.723061 seconds (25.45 M allocations: 155.874 GiB, 0.41% gc time)\nProfileLikelihoodSolution. MLE retcode: Failure\nConfidence intervals: \n     95.0% CI for k: (8.788003299163778, 10.094019297587579)\n     95.0% CI for u₀: (49.44377511158833, 50.03883730450469)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The confidence intervals contain the true values. We can now visualise.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"fig = plot_profiles(prof; nrow=1, ncol=3,\n    latex_names=[L\"k\", L\"u_0\"],\n    true_vals=[k[1], u₀],\n    fig_kwargs=(fontsize=38, resolution=(1441.9216f0, 470.17322f0)),\n    axis_kwargs=(width=600, height=300))\nscatter!(fig.content[1], get_parameter_values(prof, :k), get_profile_values(prof, :k), color=:black, markersize=9)\nscatter!(fig.content[2], get_parameter_values(prof, :u₀), get_profile_values(prof, :u₀), color=:black, markersize=9)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"(Image: Second set of profiles)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"See that we've recovered the parameters in the confidence intervals, and the profiles are smooth – the identifiability issues are gone. So, it seems like c was the problematic parameter, since our summary statistic does not really give us any information about it. Our idea of using the summary statistic mathcal S(t) from above would likely ameliorate this issue, since it will give information directly relating to c.","category":"page"},{"location":"heat/#Comparing-methods-for-constructing-initial-estimates-when-profiling","page":"Example IV: Diffusion equation on a square plate","title":"Comparing methods for constructing initial estimates when profiling","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"In the mathematical details section at the end of this README, it is mentioned that initial values for boldsymbolomega_j (the parameters to be optimised while an interest parameter is held fixed) can currently be set in two ways:","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Method 1: Simply starting boldsymbolomega_j at boldsymbolomega_j-1. This is the next_initial_estimate_method = :prev option in profile, and is the default.\nMethod 2: Using linear interpolation, we can use the previous two values and set boldsymbolomega_j = boldsymbolomega_j-2(psi_j-1 - psi_j) + boldsymbolomega_j-1(psi_j - psi_j-2)  (psi_j-1 - psi_j-2) (if boldsymbolomega_j then starts outside of the parameter bounds, we fall back to the first method). This is the next_initial_estimate_method = :interp option in profile.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Is there a big difference in these methods? Let's demonstrate if there is any difference by doing some benchmarking. We will also compare multithreading versus no multithreading.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"bnch_prev_serial = @benchmark profile($likprob_2, $mle_sol; ftol_abs=$1e-4, ftol_rel=$1e-4, xtol_abs=$1e-4, xtol_rel=$1e-4, parallel=$false, next_initial_estimate_method=$:prev)\nbnch_interp_serial = @benchmark profile($likprob_2, $mle_sol; ftol_abs=$1e-4, ftol_rel=$1e-4, xtol_abs=$1e-4, xtol_rel=$1e-4, parallel=$false, next_initial_estimate_method=$:interp)\nbnch_prev_parallel = @benchmark profile($likprob_2, $mle_sol; ftol_abs=$1e-4, ftol_rel=$1e-4, xtol_abs=$1e-4, xtol_rel=$1e-4, parallel=$true, next_initial_estimate_method=$:prev)\nbnch_interp_parallel = @benchmark profile($likprob_2, $mle_sol; ftol_abs=$1e-4, ftol_rel=$1e-4, xtol_abs=$1e-4, xtol_rel=$1e-4, parallel=$true, next_initial_estimate_method=$:interp)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Here are the results:","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"julia> bnch_prev_serial\nBenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 855.578 s (0.23% GC) to evaluate,\n with a memory estimate of 155.70 GiB, over 24670284 allocations.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"julia> bnch_interp_serial\nBenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 757.444 s (0.24% GC) to evaluate,\n with a memory estimate of 144.34 GiB, over 22976564 allocations.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"julia> bnch_prev_parallel\nBenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 548.814 s (0.34% GC) to evaluate,\n with a memory estimate of 155.87 GiB, over 25443078 allocations.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"julia> bnch_interp_parallel\nBenchmarkTools.Trial: 1 sample with 1 evaluation.\n Single result which took 498.408 s (0.36% GC) to evaluate,\n with a memory estimate of 144.52 GiB, over 23809418 allocations.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"We see that linear interpolation is a significant help to the algorithm, saving 100 seconds when we profile without multithreading, and 50 seconds when we profile with multithreading. In summary, profiling with the :interp method was about 12% faster than :prev without multithreading, and about 10% faster with multithreading –- interpolation is certainly a big help. For problems where the likelihood function is much faster to compute, these results may be opposite – it is worth thinking about this for your applications.","category":"page"},{"location":"heat/#Prediction-intervals-for-the-mass","page":"Example IV: Diffusion equation on a square plate","title":"Prediction intervals for the mass","text":"","category":"section"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us now consider propagating the uncertainty in k and u_0 into computing prediction intervals for tilde M(t) at each t. This is done using the get_prediction_intervals function introduced in the second example. First, we must define our prediction function.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"@inline function compute_mass_function(θ::AbstractVector{T}, data) where {T}\n    k, u₀ = θ\n    (; c, prob, t, alg, jac) = data\n    prob.flux_parameters[1] = k\n    pts = FiniteVolumeMethod.get_points(prob)\n    for i in axes(pts, 2)\n        pt = get_point(pts, i)\n        prob.initial_condition[i] = gety(pt) ≤ c ? u₀ : zero(T)\n    end\n    sol = solve(prob, alg; saveat=t, parallel=true, jac_prototype=jac)\n    shape_cache = zeros(T, 3)\n    mass_cache = zeros(T, length(sol.u))\n    compute_mass!(mass_cache, shape_cache, sol, prob)\n    return mass_cache\nend","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now let's get the intervals.","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"t_many_pts = LinRange(prob.initial_time, prob.final_time, 250)\njac = FiniteVolumeMethod.jacobian_sparsity(prob)\nprediction_data = (c=c, prob=prob, t=t_many_pts, alg=alg, jac=jac)\nparameter_wise, union_intervals, all_curves, param_range =\n    get_prediction_intervals(compute_mass_function, prof, prediction_data; q_type=Vector{Float64})","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Now we can visualise the curves. We will also show the mass curve from the exact parameter values, as well as from the MLE. ","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"exact_soln = compute_mass_function([k[1], u₀], prediction_data)\nmle_soln = compute_mass_function(get_mle(mle_sol), prediction_data)\nfig = Figure(fontsize=38, resolution=(1360.512f0, 848.64404f0))\nalp = join('a':'z')\nlatex_names = [L\"k\", L\"u_0\"]\nfor i in 1:2\n    ax = Axis(fig[1, i], title=L\"(%$(alp[i])): Profile-wise PI for %$(latex_names[i])\",\n        titlealign=:left, width=600, height=300)\n    [lines!(ax, t_many_pts, all_curves[i][j], color=:grey) for j in eachindex(param_range[1])]\n    lines!(ax, t_many_pts, exact_soln, color=:red)\n    lines!(ax, t_many_pts, mle_soln, color=:blue, linestyle=:dash)\n    lines!(ax, t_many_pts, getindex.(parameter_wise[i], 1), color=:black)\n    lines!(ax, t_many_pts, getindex.(parameter_wise[i], 2), color=:black)\nend\nax = Axis(fig[2, 1:2], title=L\"(c):$ $ Union of all intervals\",\n    titlealign=:left, width=1200, height=300)\nband!(ax, t_many_pts, getindex.(union_intervals, 1), getindex.(union_intervals, 2), color=:grey)\nlines!(ax, t_many_pts, getindex.(union_intervals, 1), color=:black)\nlines!(ax, t_many_pts, getindex.(union_intervals, 2), color=:black)\nlines!(ax, t_many_pts, exact_soln, color=:red)\nlines!(ax, t_many_pts, mle_soln, color=:blue, linestyle=:dash)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"Let us also add onto these plots the intervals coming from the full likelihood. (The reason to just not do this everytime in applications is because the code below takes a very long time to compute - a lifetime compared to the profile-wise intervals above.)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"lb = [8.0, 45.0]\nub = [11.0, 50.0]\nN = 1e4\ngrid = [[lb[i] + (ub[i] - lb[i]) * rand() for _ in 1:N] for i in 1:2]\ngrid = permutedims(reduce(hcat, grid), (2, 1))\nig = IrregularGrid(lb, ub, grid)\ngs, lik_vals = grid_search(likprob_2, ig; parallel=Val(true), save_vals=Val(true))\nlik_vals .-= get_maximum(mle_sol) # normalised \nfeasible_idx = findall(lik_vals .> ProfileLikelihood.get_chisq_threshold(0.95)) # values in the confidence region \nparameter_evals = grid[:, feasible_idx]\nq = [compute_mass_function(θ, prediction_data) for θ in eachcol(parameter_evals)]\nq_mat = reduce(hcat, q)\nq_lwr = minimum(q_mat; dims=2) |> vec\nq_upr = maximum(q_mat; dims=2) |> vec\nlines!(ax, t_many_pts, q_lwr, color=:magenta)\nlines!(ax, t_many_pts, q_upr, color=:magenta)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"(Image: Prediction intervals for the mass)","category":"page"},{"location":"heat/","page":"Example IV: Diffusion equation on a square plate","title":"Example IV: Diffusion equation on a square plate","text":"The exact curve has been recovered by our profile likelihood results, and the uncertainty is extremely small. Moreover, the intervals are indeed close to the interval obtained the full profile likelihood as we would hope.","category":"page"},{"location":"interface/#Interface","page":"Interface","title":"Interface","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"The interface for defining a likelihood problem builds on top of Optimization.jl. Below we list the three main structs that we use, with LikelihoodProblem the most important one and the only one that needs to be directly defined. Examples of how we use these structs are given later, and much extra functionality is given in the tests. Complete docstrings are given in the sidebar.","category":"page"},{"location":"interface/#LikelihoodProblem:-Defining-the-likelihood-problem","page":"Interface","title":"LikelihoodProblem: Defining the likelihood problem","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"The LikelihoodProblem is the definition of a likelihood function, and provides the following constructor:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"LikelihoodProblem(loglik::Function, θ₀;\n    syms=eachindex(θ₀), data=SciMLBase.NullParameters(),\n    f_kwargs=nothing, prob_kwargs=nothing)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Here, loglik is a function for the log-likelihood, taking the form ℓ(θ, p). The second argument, θ₀, is the initial estimate for the parameter values. You can provide symbolic names for the parameters via syms, so that e.g. prob[:α] (where prob is a LikelihoodProblem with :α ∈ syms) returns the initial estimate for :α. The argument p in the likelihood function can be used to pass data or other parameters into the argument, and the keyword argument data can be used for this. Lastly, f_kwargs and prob_kwargs are additional keyword arguments for the OptimizationFunction and OptimizationProblem, respectively; see the Optimization.jl documentation for more detail here.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"We also provide a simple interface for defining a log-likelihood that requires the solution of a differential equation:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"LikelihoodProblem(loglik::Function, θ₀,\n    ode_function, u₀, tspan;\n    syms=eachindex(θ₀), data=SciMLBase.NullParameters(),\n    ode_parameters=SciMLBase.NullParameters(), ode_alg,\n    ode_kwargs=nothing, f_kwargs=nothing, prob_kwargs=nothing)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Importantly, loglik in this case is now a function of the form ℓ(θ, p, integrator), where integrator is the same integrator as in the integrator interface from DifferentialEquations.jl; see the documentation at DifferentialEquations.jl for more detail on using the integrator. Furthermore, ode_function is the function for the ODE, u₀ its initial condition, and tspan its time span. Additionally, the parameters for the ode_function (e.g. the p in ode_function(du, u, p, t) or ode_function(u, p, t)) can be passed using the keyword argument ode_parameters. The algorithm used to solve the differential equation is passed with ode_alg, and lastly any additional keyword arguments for solving the problem are to be passed through ode_kwargs. ","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The full docstrings for the three methods available are given in the sidebar.","category":"page"},{"location":"interface/#LikelihoodSolution:-Obtaining-an-MLE","page":"Interface","title":"LikelihoodSolution: Obtaining an MLE","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"The MLEs for a given LikelihoodProblem are found using the function mle, e.g. mle(prob, Optim.LBFGS()) will optimise the likelihood function using the LBFGS algorithm from Optim.jl (see also ?mle). This function returns a LikelihoodSolution, defined by:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"struct LikelihoodSolution{N,Θ,P,M,R,A} <: AbstractLikelihoodSolution{N,P}\n    mle::Θ\n    problem::P\n    optimiser::A\n    maximum::M\n    retcode::R\nend","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"If sol isa LikelihoodSolution, then you can use the syms from your original problem to access a specific MLE, e.g. sol[:α] would return the MLE for the paramter :α.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"If you want to use multiple optimisers, i.e. a sequence of optimisers (O_1 O_2 ldots), in which O_j's initial estimate starts from the solution from the optimiser O_j-1, you can also provide a Tuple into the algorithm argument, e.g. mle(prob, (Optim.LBFGS(), NLopt.LN_NELDERMEAD)).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The full docstring for mle is given in the docstring section in the sidebar, along with the docstring for LikelihoodSolution.","category":"page"},{"location":"interface/#ProfileLikelihoodsolution:-Profiling-the-parameters","page":"Interface","title":"ProfileLikelihoodsolution: Profiling the parameters","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"The results for a profile likelihood, obtained from profile(prob, sol) (see also ?profile), are stored in a ProfileLikelihoodSolution struct:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"struct ProfileLikelihoodSolution{I,V,LP,LS,Spl,CT,CF,OM}\n    parameter_values::Dict{I,V}\n    profile_values::Dict{I,V}\n    likelihood_problem::LP\n    likelihood_solution::LS\n    splines::Dict{I,Spl}\n    confidence_intervals::Dict{I,ConfidenceInterval{CT,CF}}\n    other_mles::OM\nend","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Here, the parameter values used for each parameter are given in parameter_values, with parameter indices (or symbols) mapped to these values. Similarly, the values of the profile log-likelihood are stored in profile_values. We use a spline (see Interpolations.jl) to make the profile log-likelihood a continuous function, and these splines are given by splines. Next, the computed confidence intervals are given in confidence_intervals, with a confidence interval represented by a ConfidenceInterval struct. Lastly, since computing the profile log-likelihood function requires an optimisation problem with one variable fixed and the others free, we obtain for each profile log-likelihood value a set of optimised parameters – these parameters are given in other_mles.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"If prof is a ProfileLikelihoodSolution, then you can also call it as e.g. prof(0.5, 1) to evaluate the profile log-likelihood function of the first parameter at the point 0.5. Alternatively, prof(0.7, :α) does the same but for the parameter :α at the point 0.7. You can also index prof at a specific index (or symbol) to see the results only for that parameter, e.g. prof[1] or prof[:α]; this returns a ProfileLikelihoodSolutionView.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The full docstring for profile and related functions are given in the sidebar.","category":"page"},{"location":"interface/#Propagating-uncertainty:-Prediction-intervals","page":"Interface","title":"Propagating uncertainty: Prediction intervals","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"The confidence intervals obtained from profiling can be used to obtain approximate prediction intervals via profile-wise profile likelihoods, as defined e.g. in Simpson and Maclaren (2022), for a prediction function boldsymbol q(boldsymboltheta). These intervals can be based on varying a single parameter, or by taking the union of individual prediction intervals. The main function for this is get_prediction_intervals. Rather than explain in full detail here, please refer to the second example below (the logistic ODE example), where we reproduce the first case study of Simpson and Maclaren (2022).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The interface we use in get_prediction_intervals is not too refined currently, and is most subject to change. It works for now, but I will probably make it be more generally about predictions of vector quantities, assuming a function that returns a tuple of quantities, rather than having to deal with the case of scalar vs vector vs whatever else quantities. Ideally the interface should more easily support multithreading, and the code is not the cleanest to read either. Suggestions for this interface are especially welcome.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The full docstring for get_prediction_intervals is given in the sidebar.","category":"page"},{"location":"interface/#Plotting","page":"Interface","title":"Plotting","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"We provide a function plot_profiles that can be useful for plotting profile likelihoods. It requires that you have done ","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"using CairoMakie\nusing LaTeXString ","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"(else the function does not exist, thanks to Requires.jl). A full description of this function is given in the corresponding docstring in the sidebar.","category":"page"},{"location":"interface/#GridSearch","page":"Interface","title":"GridSearch","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"it can sometimes be useful to evaluate the likelihood function over many points prior to optimising it, e.g. to find a good initial estimate or to just obtain data at many points for the purpose of visualisation. We provide functions for this, based on either a RegularGrid or an IrregularGrid.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"A RegularGrid is a grid in which the grid for each parameter is uniformly spaced, so that the values for all parameter values to try fall on a lattice. An IrregularGrid allows for the parameters to take on whatever values you want, with the requirement that the parameter values to evaluate at are provided as a matrix with each column a different parameter set.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The function grid_search, after having defined a grid, can then be used for performing the grid search. The main method of interest is:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"grid_search(prob::LikelihoodProblem, grid::AbstractGrid; save_vals=Val(false), parallel=Val(false))","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Here, grid could be either a RegularGrid or an IrregularGrid. You can set save_vals=Val(true) if you want an array with all the likelihood function values, Val(false) otherwise. To enable multithreading, allowing for the evaluation of the function across different points via multiple threads, set parallel=Val(true), otherwise leave it as Val(false). The result of this grid search, if save_vals=Val(true), will be (sol, f_vals), where sol is a likelihood solution giving the parameters that gave to the highest likelihood, and f_res is the array of likelihoods at the corresponding parameters. If save_vals=Val(false), only sol is returned.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"More example is given in the examples, and complete docstrings are provided in the sidebar.","category":"page"},{"location":"logistic/#Example-II:-Logistic-ordinary-differential-equation","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"","category":"section"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"The following example comes from the first case study of Simpson and Maclaren (2022). First, load the packages we'll be using:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"using Random \nusing ProfileLikelihood\nusing Optimization \nusing OrdinaryDiffEq\nusing CairoMakie \nusing LaTeXStrings\nusing OptimizationNLopt","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Let us consider the logistic ordinary differential equation (ODE). For ODEs, our treatment is as follows: Let us have some ODE mathrm dymathrm dt = f(y t boldsymbol theta) for some parameters boldsymboltheta of interest. We will suppose that we have some data y_i^o at time t_i, i=1ldotsn, with initial condition y_0^o at time t_0=0, which we model according to a normal distribution y_i^o mid boldsymbol theta sim mathcal N(y_i(boldsymbol theta) sigma^2), i=01ldotsn, where y_i is a solution of the ODE at time t_i. This defines a likelihood that we can use for estimating the parameters.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Let us now proceed with our example. We are considering mathrm dumathrm dt = lambda u(1-uK), u(0)=u_0, and our interest is in estimating (lambda K u_0), we will fix the standard deviation of the noise, sigma, at sigma=10. Note that the exact solution to this ODE is u(t) = Ku_0(K-u_0)mathrme^-lambda t + u_0.","category":"page"},{"location":"logistic/#Data-generation-and-setting-up-the-problem","page":"Example II: Logistic ordinary differential equation","title":"Data generation and setting up the problem","text":"","category":"section"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"The first step is to generate the data.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"using OrdinaryDiffEq, Random\nλ = 0.01\nK = 100.0\nu₀ = 10.0\nt = 0:100:1000\nσ = 10.0\n@inline function ode_fnc(u, p, t)\n    λ, K = p\n    du = λ * u * (1 - u / K)\n    return du\nend\n# Initial data is obtained by solving the ODE \ntspan = extrema(t)\np = (λ, K)\nprob = ODEProblem(ode_fnc, u₀, tspan, p)\nsol = solve(prob, Rosenbrock23(), saveat=t)\nRandom.seed!(2828)\nuᵒ = sol.u + σ * randn(length(t))","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Now having our data, we define the likelihood function.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"@inline function loglik_fnc2(θ, data, integrator)\n    λ, K, u₀ = θ\n    uᵒ, σ = data\n    integrator.p[1] = λ\n    integrator.p[2] = K\n    reinit!(integrator, u₀)\n    solve!(integrator)\n    return gaussian_loglikelihood(uᵒ, integrator.sol.u, σ, length(uᵒ))\nend","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Now we can define our problem. We constrain the problem so that 0 leq lambda leq 005, 50 leq K leq 150, and 0 leq u_0 leq 50.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"lb = [0.0, 50.0, 0.0] # λ, K, u₀\nub = [0.05, 150.0, 50.0]\nθ₀ = [λ, K, u₀]\nsyms = [:λ, :K, :u₀]\nprob = LikelihoodProblem(\n    loglik_fnc2, θ₀, ode_fnc, u₀, maximum(t); # Note that u₀ is just a placeholder IC in this case since we are estimating it\n    syms=syms,\n    data=(uᵒ, σ),\n    ode_parameters=[1.0, 1.0], # temp values for [λ, K]\n    ode_kwargs=(verbose=false, saveat=t),\n    f_kwargs=(adtype=Optimization.AutoFiniteDiff(),),\n    prob_kwargs=(lb=lb, ub=ub),\n    ode_alg=Rosenbrock23()\n)","category":"page"},{"location":"logistic/#Parameter-estimation","page":"Example II: Logistic ordinary differential equation","title":"Parameter estimation","text":"","category":"section"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Now we find the MLEs.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"using OptimizationNLopt\nsol = mle(prob, NLopt.LD_LBFGS)\nLikelihoodSolution. retcode: Failure\nMaximum likelihood: -38.99053694428977\nMaximum likelihood estimates: 3-element Vector{Float64}\n     λ: 0.010438031266786045\n     K: 99.59921873132551\n     u₀: 8.098422110755225","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"We can now profile. ","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"prof = profile(prob, sol; alg=NLopt.LN_NELDERMEAD, parallel=false)\nProfileLikelihoodSolution. MLE retcode: Failure\nConfidence intervals: \n     95.0% CI for λ: (0.006400992274213644, 0.01786032876226762)\n     95.0% CI for K: (90.81154862835605, 109.54214763511888)\n     95.0% CI for u₀: (1.5919805025139593, 19.070831536649305)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"@test λ ∈ get_confidence_intervals(prof, :λ)\n@test K ∈ prof.confidence_intervals[2]\n@test u₀ ∈ get_confidence_intervals(prof, 3)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"We can visualise as we did before:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"using CairoMakie, LaTeXStrings\nfig = plot_profiles(prof;\n    latex_names=[L\"\\lambda\", L\"K\", L\"u_0\"],\n    show_mles=true,\n    shade_ci=true,\n    nrow=1,\n    ncol=3,\n    true_vals=[λ, K, u₀],\n    fig_kwargs=(fontsize=30, resolution=(2109.644f0, 444.242f0)),\n    axis_kwargs=(width=600, height=300))","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"(Image: Logistic profiles)","category":"page"},{"location":"logistic/#Prediction-intervals","page":"Example II: Logistic ordinary differential equation","title":"Prediction intervals","text":"","category":"section"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Let us now use these results to compute prediction intervals for u(t). Following Simpson and Maclaren (2022), the idea is to use the profile likelihood to construct another profile likelihood, called the profile-wise profile likelihood, that allows us to obtain prediction intervals for some prediction function q(boldsymbol theta). More detail is given in the mathematical details section.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"The first step is to define a function q(boldsymboltheta) that comptues our prediction given some parameters boldsymboltheta. The function in this case is simply:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"function prediction_function(θ, data)\n    λ, K, u₀ = θ\n    t = data\n    prob = ODEProblem(ode_fnc, u₀, extrema(t), (λ, K))\n    sol = solve(prob, Rosenbrock23(), saveat=t)\n    return sol.u\nend","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Note that the second argument data allows for extra parameters to be passed. To now obtain prediction intervals for sol.u, for each t, we define a large grid for t and use get_prediction_intervals:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"t_many_pts = LinRange(extrema(t)..., 1000)\nparameter_wise, union_intervals, all_curves, param_range =\n    get_prediction_intervals(prediction_function, prof,\n        t_many_pts; q_type=Vector{Float64})\n# t_many_pts is the `data` argument, it doesn't have to be time for other problems","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"This function get_prediction_intervals has four outputs:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"parameter_wise: These are prediction intervals for the prediction at each point t, coming from the profile likelihood of each respective parameter:","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"julia> parameter_wise\nDict{Int64, Vector{ConfidenceInterval{Float64, Float64}}} with 3 entries:\n  2 => [ConfidenceInterval{Float64, Float64}(6.45444, 12.0694, 0.95), ConfidenceInterval{Float64, Float64}(6.52931, 12.1545, 0.95), ConfidenceInterval{Float64, Float64}(6.60498, 12.24, 0.95), ConfidenceInterva…  3 => [ConfidenceInterval{Float64, Float64}(1.59389, 19.0709, 0.95), ConfidenceInterval{Float64, Float64}(1.621, 19.1773, 0.95), ConfidenceInterval{Float64, Float64}(1.64856, 19.2842, 0.95), ConfidenceInterva…  1 => [ConfidenceInterval{Float64, Float64}(1.86302, 17.5828, 0.95), ConfidenceInterval{Float64, Float64}(1.89596, 17.6768, 0.95), ConfidenceInterval{Float64, Float64}(1.92948, 17.7712, 0.95), ConfidenceInter…","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"For example, parameter_wise[1] comes from varying lambda, with the parameters K and u_0 coming from optimising the likelihood function with lambda fixed.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"union_intervals: These are prediction intervals at each point t coming from taking the union of the intervals from the corresponding elements of parameter_wise.\nall_curves: The intervals come from taking extrema over many curves. This is a Dict mapping parameter indices to the curves that were used, with all_curves[i][j] being the set of curves for the ith parameter (e.g. i=1 is for lambda) and the jth parameter.\nparam_range: The curves come from evaluating the prediction function between the bounds of the confidence intervals for each parameter, and this output gives the parameters used, so that e.g. all_curves[i][j] uses param_range[i][j] for the value of the ith parameter.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Let us now use these outputs to visualise the prediction intervals. First, let us extract the solution with the true parameter values and with the MLEs.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"exact_soln = prediction_function([λ, K, u₀], t_many_pts)\nmle_soln = prediction_function(get_mle(sol), t_many_pts)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"Now let us plot the prediction intervals coming from each parameter, and from the union of all intervals (not shown yet, see below).","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"fig = Figure(fontsize=38, resolution=(1402.7681f0, 848.64404f0))\nalp = join('a':'z')\nlatex_names = [L\"\\lambda\", L\"K\", L\"u_0\"]\nfor i in 1:3\n    ax = Axis(fig[i < 3 ? 1 : 2, i < 3 ? i : 1], title=L\"(%$(alp[i])): Profile-wise PI for %$(latex_names[i])\",\n        titlealign=:left, width=600, height=300)\n    [lines!(ax, t_many_pts, all_curves[i][j], color=:grey) for j in eachindex(param_range[1])]\n    lines!(ax, t_many_pts, exact_soln, color=:red)\n    lines!(ax, t_many_pts, mle_soln, color=:blue, linestyle=:dash)\n    lines!(ax, t_many_pts, getindex.(parameter_wise[i], 1), color=:black, linewidth=3)\n    lines!(ax, t_many_pts, getindex.(parameter_wise[i], 2), color=:black, linewidth=3)\nend\nax = Axis(fig[2, 2], title=L\"(d):$ $ Union of all intervals\",\n    titlealign=:left, width=600, height=300)\nband!(ax, t_many_pts, getindex.(union_intervals, 1), getindex.(union_intervals, 2), color=:grey)\nlines!(ax, t_many_pts, getindex.(union_intervals, 1), color=:black, linewidth=3)\nlines!(ax, t_many_pts, getindex.(union_intervals, 2), color=:black, linewidth=3)\nlines!(ax, t_many_pts, exact_soln, color=:red)\nlines!(ax, t_many_pts, mle_soln, color=:blue, linestyle=:dash)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"To now assess the coverage of these intervals, we want to compare them to the interval coming from the full likelihood. We find this interval by taking a large number of parameters, and finding all of them for which the normalised log-likelihood exceeds the threshold -192. We then take the parameters that give a value exceeding this threshold, compute the prediction function at these values, and then take the extrema. The code below uses the function grid_search that evaluates the function at many points, and we describe this function in more detail in the next example.","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"lb = get_lower_bounds(prob)\nub = get_upper_bounds(prob)\nN = 1e5\ngrid = [[lb[i] + (ub[i] - lb[i]) * rand() for _ in 1:N] for i in 1:3]\ngrid = permutedims(reduce(hcat, grid), (2, 1))\nig = IrregularGrid(lb, ub, grid)\ngs, lik_vals = grid_search(prob, ig; parallel=Val(true), save_vals=Val(true))\nlik_vals .-= get_maximum(sol) # normalised \nfeasible_idx = findall(lik_vals .> ProfileLikelihood.get_chisq_threshold(0.95)) # values in the confidence region \nparameter_evals = grid[:, feasible_idx]\nq = [prediction_function(θ, t_many_pts) for θ in eachcol(parameter_evals)]\nq_mat = reduce(hcat, q)\nq_lwr = minimum(q_mat; dims=2) |> vec\nq_upr = maximum(q_mat; dims=2) |> vec\nlines!(ax, t_many_pts, q_lwr, color=:magenta, linewidth=3)\nlines!(ax, t_many_pts, q_upr, color=:magenta, linewidth=3)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"(Image: Logistic prediction intervals)","category":"page"},{"location":"logistic/","page":"Example II: Logistic ordinary differential equation","title":"Example II: Logistic ordinary differential equation","text":"The first plot shows that the profile-wise prediction interval for lambda is quite large when t is small, and then small for large time. This makes sense since the large time solution is independent of lambda (the large time solution is u_s(t)=K). For K, we see that the profile-wise interval only becomes large for large time, which again makes sense. For u_0 we see similar behaviour as for lambda. Finally, taking the union over all the intervals, as is done in (d), shows that we fully enclose the solution coming from the MLE, as well as the true curve. The magenta curve shows the results from the full likelihood function, and is reasonably close to the approximate interval obtained from the union.","category":"page"},{"location":"math/#Mathematical-and-Implementation-Details","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"","category":"section"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"We now give some of the mathematical and implementation details used in this package, namely for computing the profile likelihood function and for computing prediction intervals.","category":"page"},{"location":"math/#Computing-the-profile-likelihood-function","page":"Mathematical and Implementation Details","title":"Computing the profile likelihood function","text":"","category":"section"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Let us start by giving a mathematical description of the method that we use for computing the profile log-likelihood function. Suppose that we have a parameter vector boldsymboltheta that we partition as boldsymbol theta = (psi boldsymbol omega) (psi is a scalar in this description, since we only support univariate profiles currently). We suppose that we have a likelihood function mathcal L(boldsymbol theta) equiv mathcal L(psi boldsymbol omega) so that the normalised profile log-likelihood function for psi is defined as ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"hatell_p(psi) = sup_boldsymbol omega in Omega mid psi leftell(psi boldsymbolomega) - ell^*right","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"where Omega is the parameter space for boldsymbol omega, ell(psiboldsymbolomega) = mathcal L(psi boldsymbol omega), and ell^* = ell(hatboldsymbol theta), where boldsymbol theta are the MLEs for boldsymbol theta. This definition of hatell_p(psi) induces a function boldsymbolomega^*(psi) depending on psi that gives the values of boldsymbol omega leading to the supremum above, i.e. ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"ell(psi boldsymbolomega^star(psi)) = sup_boldsymbol omega in Omega mid psi leftell(psi boldsymbolomega) - ell^starright ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"To compute hatell_p(psi), then, requires a way to efficiently compute the omega^*(psi), and requires knowing where to stop computing. Where we stop computing the profile likelihood is simply when hatell_p(psi)  -chi_11-alpha^22, where alpha is the significance level (e.g. alpha=005, in which case chi_11-005^22 approx 192). This motivates a iterative algorithm, where we start at the MLE and then step left and right.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"We describe how we evaluate the function to the right of the MLE – the case of going to the left is identical. First, we define psi_1 = hatpsi, where hatpsi is the MLE for psi. This defines boldsymbolomega_1 = boldsymbolomega^star(psi_1), which in this case just gives the MLE hatboldsymboltheta = (hatpsi boldsymbolomega_1) by definition. The value of the normalised profile log-likelihood here is simply hatell_1 = hatell(psi_1) = 0. Then, defining some step size Deltapsi, we define psi_2 = psi_1 + Delta psi, and in general psi_j+1 = psi_j + Delta psi, we need to estimate boldsymbolomega_2 = boldsymbol omega^*(psi_2). We do this by starting an optimiser at the initial estimate boldsymbolomega_2 = boldsymbolomega_1 and then using this initial estimate to produce a refined value of boldsymbolomega_2 that we take as its true value. In particular, each boldsymbolomega_j comes from starting the optimiser at the previous boldsymbolomega_j-1, and the value for hatell_j = hatell(psi_j) comes from the value of the likelihood at (psi_j boldsymbolomega_j). The same holds when going to the left except with hatell_j+1 = psi_j - Deltapsi, and then rearranging the indices j when combining the results to the left and to the right.  At each step, we check if hatell_j  -chi_11-alpha^22 and, if so, we terminate. ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Once we have terminated the algorithm, we need to obtain the confidence intervals. To do this, we fit a spline to the data (psi_j hatell_j), and use a bisection algorithm over the two intervals (min_j psi_j hatpsi) and (hatpsi max_jpsi_j), to find where hatell_j = -chi_1-alpha^22. This leads to two solutions (L U) that we take together to give the confidence interval for psi. ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"This is all done for each parameter.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Note that a better method for initialising the optimisation for boldsymbolomega_j may be to use e.g. linear interpolation for the previous two values, boldsymbolomega_j-1 and boldsymbolomega_j-2 (with special care for the bounds of the parameters). We provide support for this, letting boldsymbolomega_j = boldsymbolomega_j-2(psi_j-1 - psi_j) + boldsymbolomega_j-1(psi_j - psi_j-2)  (psi_j-1 - psi_j-2). See the next_initial_estimate_method option in ?profile.","category":"page"},{"location":"math/#Computing-prediction-intervals","page":"Mathematical and Implementation Details","title":"Computing prediction intervals","text":"","category":"section"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Our method for computing prediction intervals follows Simpson and Maclaren (2022), as does our description that follows. This method is nice as it provides a means for sensitivity analysis, enabling the attribution of components of uncertainty in some prediction function q(psi boldsymbol omega) (with psi the interest parameter and boldsymbolomega the nuisance parameters as above) to individual parameters. The resulting intervals are called profile-wise intervals, with the predictions themselves called parameter-based, profile-wise predictions or profile-wise predictions.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"The idea is to take a set of profile likelihoods and the confidence intervals obtained from each, and then pushing those into a prediction function that we then use to obtain prediction intervals, making heavy use of the transformation invariance property of MLEs.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"So, let us start with some prediction function q(psi boldsymbol omega), and recall that the profile likelihood function for psi induces a function boldsymbolomega^star(psi). The profile-wise likelihood for q, given the set of values (psi boldsymbolomega^star(psi)), is defined by ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"hatell_pleft(qleft(psi boldsymbolomega^star(psi)right) = qright) = sup_psi mid  qleft(psi boldsymbolomega^star(psi)right) = q hatell_p(psi) ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Note that if q(psi boldsymbolomega^star(psi)) is injective, there is only one such psi such that qleft(psi boldsymbolomega^star(psi)right) = q for any given q in which case the profile-wise likelihood for q (based on psi) is simply hatell_p(psi). This definition is intuitive, recalling that the profile likelihood comes from a definition like the above except with the likelihood function on the right, so profile-wise likelihoods come from profile likelihoods.  Using this definition, and using the transformation invariance property of the MLE, confidence sets for psi directly translate into confidence sets for q, in particular to find a 100(1-alpha) prediction interval for q we need only evaluate q for psi inside its confidence interval.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"Let us now describe the extra details involved in obtaining these prediction intervals, in particular what we are doing in the get_prediction_intervals function. For this, we imagine that q is scalar valued, but the description below can be easily extended to the vector case (just apply the idea to each component – see the logistic ODE example). We also only explain this for a single parameter psi, but we describe how we use the results for each parameter to obtain a more conservative interval.","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"The first step is to evaluate the family of curves. If we suppose that the confidence interval for psi is (psi_L psi_U), we define psi_j = psi_L + (j-1)(psi_U - psi_L)(n_psi - 1), j=1ldotsn_psi – this is a set of n_psi equally spaced points between the interval limits. For each psi_j we need to then compute boldsymbolomega^star(psi_j). Rather than re-optimise, we use the data from our profile likelihoods, where we have stored values for (psi boldsymbolomega^star(psi)) to define a continuous function boldsymbolomega^star(psi) via linear interpolation. Using this linear interpolant we can thus compute boldsymbolomega^star(psi_j) for each gridpoint psi_j. We can therefore compute boldsymboltheta_j = (psi_j boldsymbolomega^star(psi_j)) so that we can evaluate the prediction function at each psi_j, q_j = q(boldsymboltheta_j). ","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"We now have a sample q_1 ldots q_n_psi. If we let q_L = min_j=1^n_psi q_j and q_U = max_j=1^n_psi q_j, then our prediction interval is (q_L q_U). To be more specific, this is the profile-wise interval for q given the basis (psi boldsymbolomega^star(psi)).","category":"page"},{"location":"math/","page":"Mathematical and Implementation Details","title":"Mathematical and Implementation Details","text":"We have now described how prediction intervals are obtained based on a single parameter. Suppose we do this for a collection of parameters psi^1 ldots psi^d (e.g. if boldsymboltheta = (D lambda K), then we might have computed profiles for psi^1=D, psi^2=lambda, and psi^3=K), giving d different intervals for each psi^i, say (q_L^i q_U^i)_i=1^d. We can take the union of these intervals to get a more conservative interval for the prediction, giving the new interval (min_i=1^d q_L^i max_i=1^d q_U^i).","category":"page"},{"location":"exponential/#Example-III:-Linear-exponential-ODE-and-grid-searching","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"","category":"section"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Now we consider mathrm dymathrm dt = lambda y, y(0) = y_0. This has solution y(t) = y_0mathrme^lambda t. First, load the packages we'll be using:","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"using OrdinaryDiffEq\nusing ProfileLikelihood\nusing Optimization \nusing CairoMakie \nusing LaTeXStrings \nusing Random\nusing Distributions\nusing MuladdMacro\nusing LoopVectorization\nusing LatinHypercubeSampling \nusing OptimizationOptimJL\nusing OptimizationNLopt","category":"page"},{"location":"exponential/#Setting-up-the-problem","page":"Example III: Linear exponential ODE and grid searching","title":"Setting up the problem","text":"","category":"section"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Let us start by defining the data and the likelihood problem:","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"## Step 1: Generate some data for the problem and define the likelihood\nRandom.seed!(2992999)\nλ = -0.5\ny₀ = 15.0\nσ = 0.5\nT = 5.0\nn = 450\nΔt = T / n\nt = [j * Δt for j in 0:n]\ny = y₀ * exp.(λ * t)\nyᵒ = y .+ [0.0, rand(Normal(0, σ), n)...]\n@inline function ode_fnc(u, p, t)\n    local λ\n    λ = p\n    du = λ * u\n    return du\nend\nusing LoopVectorization, MuladdMacro\n@inline function _loglik_fnc(θ::AbstractVector{T}, data, integrator) where {T}\n    local yᵒ, n, λ, σ, u0\n    yᵒ, n = data\n    λ, σ, u0 = θ\n    integrator.p = λ\n    ## Now solve the problem \n    reinit!(integrator, u0)\n    solve!(integrator)\n    if !SciMLBase.successful_retcode(integrator.sol)\n        return typemin(T)\n    end\n    ℓ = -0.5(n + 1) * log(2π * σ^2)\n    s = zero(T)\n    @turbo @muladd for i in eachindex(yᵒ, integrator.sol.u)\n        s = s + (yᵒ[i] - integrator.sol.u[i]) * (yᵒ[i] - integrator.sol.u[i])\n    end\n    ℓ = ℓ - 0.5s / σ^2\nend\n\n## Step 2: Define the problem\nθ₀ = [-1.0, 0.5, 19.73] # will be replaced anyway\nlb = [-10.0, 1e-6, 0.5]\nub = [10.0, 10.0, 25.0]\nsyms = [:λ, :σ, :y₀]\nprob = LikelihoodProblem(\n    loglik_fnc, θ₀, ode_fnc, y₀, (0.0, T);\n    syms=syms,\n    data=(yᵒ, n),\n    ode_parameters=1.0, # temp value for λ\n    ode_kwargs=(verbose=false, saveat=t),\n    f_kwargs=(adtype=Optimization.AutoFiniteDiff(),),\n    prob_kwargs=(lb=lb, ub=ub),\n    ode_alg=Tsit5()\n)","category":"page"},{"location":"exponential/#Grid-searching","page":"Example III: Linear exponential ODE and grid searching","title":"Grid searching","text":"","category":"section"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Let us now give an alternative way of exploring this likelihood function. We have been using mle, but we also provide some capability for using a grid search, which can sometimes be useful for e.g. visualising a likelihood function or obtaining initial estmiates for parameters (although it scales terribly for problems with more than even three parameters). Below we define a RegularGrid, a regular grid for each parameter:","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"regular_grid = RegularGrid(lb, ub, 50) # resolution can also be given as a vector for each parameter","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"We can now use this grid to evaluate the likelihood function at each point, and then return the maximum values (use save_vals=Val(true) if you want all the computed values as an array, given as a second argument; also see ?grid_search). (You can also set parallel = Val(true) so that the computation is done with multithreading.)","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"gs = grid_search(prob, regular_grid)\nLikelihoodSolution. retcode: Success\nMaximum likelihood: -547.9579886200935\nMaximum likelihood estimates: 3-element Vector{Float64}\n     λ: -0.612244897959183\n     σ: 0.816327448979592\n     y₀: 16.5","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"You could also use an irregular grid, defining some grid as a matrix where each column is a set of parameter values, or a vector of vectors. Here is an example using LatinHypercubeSampling.jl to avoid the dimensionality issue (although in practice we would have to be more careful with choosing the parameter bounds to get good coverage of the parameter space).","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"using LatinHypercubeSampling\nd = 3\ngens = 1000\nplan, _ = LHCoptim(500, d, gens)\nnew_lb = [-2.0, 0.05, 10.0]\nnew_ub = [2.0, 0.2, 20.0]\nbnds = [(new_lb[i], new_ub[i]) for i in 1:d]\nparameter_vals = Matrix(scaleLHC(plan, bnds)') # transpose so that a column is a parameter set \nirregular_grid = IrregularGrid(lb, ub, parameter_vals)\ngs_ir, loglik_vals_ir = grid_search(prob, irregular_grid; save_vals=Val(true), parallel = Val(true))","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"LikelihoodSolution. retcode: Success\nMaximum likelihood: -1729.7407123603484\nMaximum likelihood estimates: 3-element Vector{Float64}\n     λ: -0.5090180360721444\n     σ: 0.19368737474949904\n     y₀: 15.791583166332664","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"max_lik, max_idx = findmax(loglik_vals_ir)\n@test max_lik == PL.get_maximum(gs_ir)\n@test parameter_vals[:, max_idx] ≈ PL.get_mle(gs_ir)","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"(If you just want to try many points for starting your optimiser, see the optimiser in MultistartOptimization.jl.)","category":"page"},{"location":"exponential/#Parameter-estimation","page":"Example III: Linear exponential ODE and grid searching","title":"Parameter estimation","text":"","category":"section"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Now let's use mle. We will restart the initial guess to use the estimates from our grid search.","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"prob = update_initial_estimate(prob, gs)\nsol = mle(prob, Optim.LBFGS())","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Now we profile.","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"prof = profile(prob, sol; alg=NLopt.LN_NELDERMEAD, parallel = true)","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"ProfileLikelihoodSolution. MLE retcode: Success\nConfidence intervals: \n     95.0% CI for λ: (-0.51091362373969, -0.49491369219060505)\n     95.0% CI for σ: (0.49607205632240814, 0.5652591835193789)\n     95.0% CI for y₀: (14.98587355568687, 15.305179849533756)","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"@test λ ∈ get_confidence_intervals(prof, :λ)\n@test σ ∈ get_confidence_intervals(prof[:σ])\n@test y₀ ∈ get_confidence_intervals(prof, 3)","category":"page"},{"location":"exponential/#Visualisation","page":"Example III: Linear exponential ODE and grid searching","title":"Visualisation","text":"","category":"section"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"Finally, we can visualise the profiles:","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"fig = plot_profiles(prof; nrow=1, ncol=3,\n    latex_names=[L\"\\lambda\", L\"\\sigma\", L\"y_0\"],\n    true_vals=[λ, σ, y₀],\n    fig_kwargs=(fontsize=30, resolution=(2109.644f0, 444.242f0)),\n    axis_kwargs=(width=600, height=300))","category":"page"},{"location":"exponential/","page":"Example III: Linear exponential ODE and grid searching","title":"Example III: Linear exponential ODE and grid searching","text":"(Image: Linear exponential profiles)","category":"page"},{"location":"#ProfileLikelihood","page":"Home","title":"ProfileLikelihood","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: DOI)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package defines the routines required for computing maximum likelihood estimates and profile likelihoods. The optimisation routines are built around the Optimization.jl interface, allowing us to e.g. easily switch between algorithms, between finite differences and automatic differentiation, and it allows for constraints to be defined with ease. Below we list the definitions we are using for likelihoods and profile likelihoods. This code only works for scalar parameters of interest (i.e. out of a vector boldsymbol theta, you can profile a single scalar parameter theta_i in boldsymboltheta) for now. We use the following definitions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Definition: Likelihood function (see Casella & Berger, 2002): Let f(boldsymbol x mid boldsymbol theta) denote the joint probability density function (PDF) of the sample boldsymbol X = (X_1ldotsX_n)^mathsf T, where boldsymbol theta in Theta is some set of parameters and Theta is the parameter space. We define the likelihood function mathcal L colon Theta to 0 infty) by mathcal L(boldsymbol theta mid boldsymbol x) = f(boldsymbol x mid boldsymbol theta) for some realisation boldsymbol x = (x_1ldotsx_n)^mathsf T of boldsymbol X. The log-likelihood function ellcolonThetatomathbb R is defined by ell(boldsymbol theta mid boldsymbol x) =  logmathcal L(boldsymboltheta mid boldsymbol x).The maximum likelihood estimate (MLE) hatboldsymboltheta is the parameter boldsymboltheta that maximises the likelihood function, hatboldsymboltheta = argmax_boldsymboltheta in Theta mathcalL(boldsymboltheta mid boldsymbol x) = argmax_boldsymboltheta in Theta ell(boldsymboltheta mid boldsymbol x).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Definition: Profile likelihood function (see Pawitan, 2001): Suppose we have some parameters of interest, boldsymbol theta in Theta, and some nuisance parameters, boldsymbol phi in Phi, and some data boldsymbol x = (x_1ldotsx_n)^mathsf T, giving some joint likelihood mathcal L colon Theta cup Phi to 0 infty) defined by mathcal L(boldsymboltheta boldsymbolphi mid boldsymbol x). We define the profile likelihood mathcal L_p colon Theta to 0 infty) of boldsymboltheta by mathcal L_p(boldsymboltheta mid boldsymbol x) = sup_boldsymbol phi in Phi mid boldsymbol theta mathcal L(boldsymbol theta boldsymbol phi mid boldsymbol x). The profile log-likelihood ell_p colon Theta to mathbb R of boldsymboltheta is defined by ell_p(boldsymbol theta mid boldsymbol x) = log mathcal L_p(boldsymboltheta mid boldsymbol x). The normalised profile likelihood is defined by hatmathcal L_p(boldsymboltheta mid boldsymbol x) = mathcal L_p(boldsymbol theta mid boldsymbol x) - mathcal L_p(hatboldsymboltheta mid boldsymbol x), where hatboldsymboltheta is the MLE of boldsymboltheta, and similarly for the normalised profile log-likelihood.","category":"page"},{"location":"","page":"Home","title":"Home","text":"From Wilk's theorem, we know that 2hatell_p(boldsymboltheta mid boldsymbol x) geq -chi_p 1-alpha^2 is an approximate 100(1-alpha) confidence region for boldsymbol theta, and this enables us to obtain confidence intervals for parameters by considering only their profile likelihood, where chi_p1-alpha^2 is the 1-alpha quantile of the chi_p^2 distribution and p is the length of boldsymboltheta. For the case of a scalar parameter of interest, -chi_1 095^2 approx -192.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We compute the profile log-likelihood in this package by starting at the MLE, and stepping left/right until we reach a given threshold. The code is iterative to not waste time in so much of the parameter space.","category":"page"},{"location":"","page":"Home","title":"Home","text":"More detail about the methods we use in this package is given in the following sections, with extra detail in the tests.","category":"page"},{"location":"docstrings/#Docstrings","page":"Docstrings","title":"Docstrings","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"Here we give some of the main docstrings. ","category":"page"},{"location":"docstrings/#LikelihoodProblem","page":"Docstrings","title":"LikelihoodProblem","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"ProfileLikelihood.AbstractLikelihoodProblem \nLikelihoodProblem","category":"page"},{"location":"docstrings/#ProfileLikelihood.AbstractLikelihoodProblem","page":"Docstrings","title":"ProfileLikelihood.AbstractLikelihoodProblem","text":"abstract type AbstractLikelihoodProblem{N, L}\n\nAbstract type of a likelihood problem, where N is the number of parameters and  L is the type of the likelihood function.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.LikelihoodProblem","page":"Docstrings","title":"ProfileLikelihood.LikelihoodProblem","text":"LikelihoodProblem{N,P,D,L,Θ,S} <: AbstractLikelihoodProblem\n\nStruct representing a likelihood problem. \n\nFields\n\nproblem::P\n\nThe associated OptimizationProblem.\n\ndata::D\n\nThe argument p used in the log-likelihood function. \n\nlog_likelihood_function::L\n\nThe log-likelihood function, taking the form ℓ(θ, p).\n\nθ₀::Θ\n\nInitial estimates for the MLE θ.\n\nsyms::S\n\nVariable names for the parameters.\n\nThe extra parameter N is the number of parameters.\n\nConstructors\n\nStandard\n\nLikelihoodProblem(loglik::Function, θ₀;\n    syms=eachindex(θ₀), data=SciMLBase.NullParameters(),\n    f_kwargs=nothing, prob_kwargs=nothing)\n\nConstructor for the LikelihoodProblem.\n\nArguments\n\nloglik::Function: The log-likelihood function, taking the form ℓ(θ, p).\nθ₀: The estimates estimates for the MLEs.\n\nKeyword Arguments\n\nsyms=eachindex(θ₀): Names for each parameter. \ndata=SciMLBase.NullParameters(): The parameter p in the log-likelihood function. \nf_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationFunction.\nprob_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationProblem.\n\nOutputs\n\nReturns the LikelihoodProblem problem object.\n\nWith arguments for a differential equation problem\n\nLikelihoodProblem(loglik::Function, θ₀,\n    ode_function, u₀, tspan;\n    syms=eachindex(θ₀), data=SciMLBase.NullParameters(),\n    ode_parameters=SciMLBase.NullParameters(), ode_alg,\n    ode_kwargs=nothing, f_kwargs=nothing, prob_kwargs=nothing)\n\nConstructor for the LikelihoodProblem for a differential equation problem.\n\nArguments\n\nloglik::Function: The log-likelihood function, taking the form ℓ(θ, p, integrator).\nθ₀: The estimates estimates for the MLEs.\node_function: The function f(du, u, p, t) or f(u, p, t) for the differential equation.\nu₀: The initial condition for the differential equation. \ntspan: The time-span to solve the differential equaton over. \n\nKeyword Arguments\n\nsyms=eachindex(θ₀): Names for each parameter. \ndata=SciMLBase.NullParameters(): The parameter p in the log-likelihood function. \node_parameters=SciMLBase.NullParameters(): The parameter p in ode_function.\node_alg: The algorithm used for solving the differential equatios.\node_kwargs=nothing: Extra keyword arguments, passed as a NamedTuple, to pass into the integrator; see construct_integrator.\nf_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationFunction.\nprob_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationProblem.\n\nOutputs\n\nReturns the LikelihoodProblem problem object.\n\nWith an integrator\n\nLikelihoodProblem(loglik::Function, θ₀, integrator;\n    syms=eachindex(θ₀), data=SciMLBase.NullParameters(),\n    f_kwargs=nothing, prob_kwargs=nothing)\n\nConstructor for the LikelihoodProblem for a differential equation problem  with associated integrator.\n\nArguments\n\nloglik::Function: The log-likelihood function, taking the form ℓ(θ, p, integrator).\nθ₀: The estimates estimates for the MLEs.\nintegrator: The integrator for the differential equation problem. See also construct_integrator.\n\nKeyword Arguments\n\nsyms=eachindex(θ₀): Names for each parameter. \ndata=SciMLBase.NullParameters(): The parameter p in the log-likelihood function. \nf_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationFunction.\nprob_kwargs=nothing: Keyword arguments, passed as a NamedTuple, for the OptimizationProblem.\n\nOutputs\n\nReturns the LikelihoodProblem problem object.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#LikelihoodSolution","page":"Docstrings","title":"LikelihoodSolution","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"ProfileLikelihood.AbstractLikelihoodSolution\nProfileLikelihood.LikelihoodSolution \nmle","category":"page"},{"location":"docstrings/#ProfileLikelihood.AbstractLikelihoodSolution","page":"Docstrings","title":"ProfileLikelihood.AbstractLikelihoodSolution","text":"abstract type AbstractLikelihoodSolution{N, P}\n\nType representing the solution to a likelihood problem, where N is the  number of parameters and P is the type of the likelihood problem.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.LikelihoodSolution","page":"Docstrings","title":"ProfileLikelihood.LikelihoodSolution","text":"struct LikelihoodSolution{Θ,P,M,R,A} <: AbstractLikelihoodSolution\n\nStruct for a solution to a LikelihoodProblem.\n\nFields\n\nmle::Θ: The MLEs.\nproblem::P: The LikelihoodProblem.\noptimiser::A: The algorithm used for solving the optimisation problem. \nmaximum::M: The maximum likelihood. \nretcode::R: The SciMLBase.ReturnCode.\n\nConstructors\n\nLikelihoodSolution(sol::SciMLBase.OptimizationSolution, prob::AbstractLikelihoodProblem; alg=sol.alg)\n\nConstructs the likelihood solution from a solution to an OptimizationProblem with a given LikelihoodProblem.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.mle","page":"Docstrings","title":"ProfileLikelihood.mle","text":"mle(prob::LikelihoodProblem, alg, args...; kwargs...)\nmle(prob::LikelihoodProblem, alg::Tuple, args...; kwargs...)\n\nGiven the likelihood problem prob and an optimiser alg, finds the MLEs and returns a  LikelihoodSolution object. Extra arguments and keyword arguments for solve can be passed  through args... and kwargs....\n\nIf alg is a Tuple, then the problem is re-optimised after each algorithm with the next element in alg,  starting from alg[1], with initial estimate coming from the solution with the  previous algorithm (starting with get_initial_estimate(prob)).\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#ProfileLikelihoodSolution","page":"Docstrings","title":"ProfileLikelihoodSolution","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"ProfileLikelihood.ProfileLikelihoodSolution \nProfileLikelihood.ConfidenceInterval\nprofile \nreplace_profile!\nProfileLikelihood.set_next_initial_estimate!","category":"page"},{"location":"docstrings/#ProfileLikelihood.ProfileLikelihoodSolution","page":"Docstrings","title":"ProfileLikelihood.ProfileLikelihoodSolution","text":"ProfileLikelihoodSolution{I,V,LP,LS,Spl,CT,CF,OM}\n\nStruct for the normalised profile log-likelihood. See profile for a constructor.\n\nFields\n\nθ::Dict{I, V}: This is a dictionary such that θ[i] gives the parameter values used for the normalised profile log-likelihood of the ith variable.\nprofile::Dict{I, V}: This is a dictionary such that profile[i] gives the values of the normalised profile log-likelihood function at the corresponding values in θ[i].\nprob::LP: The original LikelihoodProblem.\nmle::LS: The solution to the full problem.\nspline::Dict{I, Spl}: This is a dictionary such that spline[i] is a spline through the data (θ[i], profile[i]). This spline can be evaluated at a point ψ for the ith variable by calling an instance of the struct with arguments (ψ, i). See also spline_profile.\nconfidence_intervals::Dict{I,ConfidenceInterval{CT,CF}}: This is a dictonary such that confidence_intervals[i] is a confidence interval for the ith parameter.\nother_mles::OM: This is a dictionary such that other_mles[i] gives the vector for the MLEs of the other parameters not being profiled, for each datum.\n\nSpline evaluation\n\nThis struct is callable. We define the method \n\n(prof::ProfileLikelihoodSolution)(θ, i)\n\nthat evaluates the spline through the ith profile at the point θ.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.ConfidenceInterval","page":"Docstrings","title":"ProfileLikelihood.ConfidenceInterval","text":"struct ConfidenceInterval{T, F}\n\nStruct representing a confidence interval. \n\nFields\n\nlower::T: The lower bound of the confidence interval. \nupper::T: The upper bound of the confidence interval. \nlevel::F: The level of the confidence interval.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.profile","page":"Docstrings","title":"ProfileLikelihood.profile","text":"profile(prob::LikelihoodProblem, sol::LikelihoodSolution, n=1:number_of_parameters(prob);\n    alg=get_optimiser(sol),\n    conf_level::F=0.95,\n    confidence_interval_method=:spline,\n    threshold=get_chisq_threshold(conf_level),\n    resolution=200,\n    param_ranges=construct_profile_ranges(sol, get_lower_bounds(prob), get_upper_bounds(prob), resolution),\n    min_steps=10,\n    normalise::Bool=true,\n    spline_alg=FritschCarlsonMonotonicInterpolation,\n    extrap=Line,\n    parallel=false,\n    next_initial_estimate_method = :prev,\n    kwargs...)\n\nComputes profile likelihoods for the parameters from a likelihood problem prob with MLEs sol.\n\nSee also replace_profile! which allows you to re-profile a parameter in case you are not satisfied with  the results. \n\nArguments\n\nprob::LikelihoodProblem: The LikelihoodProblem.\nsol::LikelihoodSolution: The LikelihoodSolution. See also mle.\nn=1:number_of_parameters(prob): The parameter indices to compute the profile likelihoods for.\n\nKeyword Arguments\n\nalg=get_optimiser(sol): The optimiser to use for solving each optimisation problem. \nconf_level::F=0.95: The level to use for the ConfidenceIntervals.\nconfidence_interval_method=:spline: The method to use for computing the confidence intervals. See also get_confidence_intervals!. The default :spline uses rootfinding on the spline through the data, defining a continuous function, while the alternative :extrema simply takes the extrema of the values that exceed the threshold.\nthreshold=get_chisq_threshold(conf_level): The threshold to use for defining the confidence intervals. \nresolution=200: The number of points to use for evaluating the profile likelihood in each direction starting from the MLE (giving a total of 400 points).\nparam_ranges=construct_profile_ranges(sol, get_lower_bounds(prob), get_upper_bounds(prob), resolution): The ranges to use for each parameter.\nmin_steps=10: The minimum number of steps to allow for the profile in each direction. If fewer than this number of steps are used before reaching threshold, then the algorithm restarts and computes the profile likelihood a number min_steps of points in that direction. \nnormalise::Bool=true: Whether to optimise the normalised profile log-likelihood or not. \nspline_alg=FritschCarlsonMonotonicInterpolation: The interpolation algorithm to use for computing a spline from the profile data. See Interpolations.jl. \nextrap=Line: The extrapolation algorithm to use for computing a spline from the profile data. See Interpolations.jl.\nparallel=false: Whether to use multithreading. If true, will use multithreading so that multiple parameters are profiled at once, and the steps to the left and right are done at the same time. \nnext_initial_estimate_method = :prev: Method for selecting the next initial estimate when stepping forward when profiling. :prev simply uses the previous solution, but you can also use :interp to use linear interpolation. See also set_next_initial_estimate!.\nkwargs...: Extra keyword arguments to pass into solve for solving the OptimizationProblem. See also the docs from Optimization.jl.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#ProfileLikelihood.replace_profile!","page":"Docstrings","title":"ProfileLikelihood.replace_profile!","text":"replace_profile!(prof::ProfileLikelihoodSolution, n);\n    alg=get_optimiser(prof.likelihood_solution),\n    conf_level::F=0.95,\n    confidence_interval_method=:spline,\n    threshold=get_chisq_threshold(conf_level),\n    resolution=200,\n    param_ranges=construct_profile_ranges(prof.likelihood_solution, get_lower_bounds(prof.likelihood_problem), get_upper_bounds(prof.likelihood_problem), resolution),\n    min_steps=10,\n    normalise::Bool=true,\n    spline_alg=FritschCarlsonMonotonicInterpolation,\n    extrap=Line,\n    parallel=false,\n    next_initial_estimate_method=:prev,\n    kwargs...) where {F}\n\nGiven an existing prof::ProfileLikelihoodSolution, replaces the profile results for the parameters in n. The keyword  arguments are the same as for profile.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#ProfileLikelihood.set_next_initial_estimate!","page":"Docstrings","title":"ProfileLikelihood.set_next_initial_estimate!","text":"set_next_initial_estimate!(sub_cache, param_vals, other_mles, prob, θₙ; next_initial_estimate_method=:prev)\n\nMethod for selecting the next initial estimate for the optimisers. sub_cache is the cache vector for placing  the initial estimate into, param_vals is the current list of parameter values for the interest parameter,  and other_mles is the corresponding list of previous optimisers. prob is the OptimizationProblem. The value  θₙ is the next value of the interest parameter.\n\nThe available methods are: \n\nnext_initial_estimate_method = :prev: If this is selected, simply use other_mles[end], i.e. the previous optimiser. \nnext_initial_estimate_method = :interp: If this is selected, the next optimiser is determined via linear interpolation using the data (param_vals[end-1], other_mles[end-1]), (param_vals[end], other_mles[end]). If the new approximation is outside of the parameter bounds, falls back to next_initial_estimate_method = :prev.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#Prediction-intervals","page":"Docstrings","title":"Prediction intervals","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"get_prediction_intervals \neval_prediction_function ","category":"page"},{"location":"docstrings/#ProfileLikelihood.get_prediction_intervals","page":"Docstrings","title":"ProfileLikelihood.get_prediction_intervals","text":"get_prediction_intervals(q, prof::ProfileLikelihoodSolution, data;\n    q_type=get_q_type(q, prof, data), resolution=250)\n\nGiven a prediction of the form q(θ, data), where θ has the same size as the θ used in  the profile likelihood solution prof, and data is the argument data, computes the prediction  intervals for q (possibly at each point if it outputs a vector) using the confidence intervals from prof. You can set the output of the prediction function using q_type, and the grid resolution when evaluating the prediction  function for each parameter via resolution.\n\nTwo results are produced:\n\nparameterwise_cis: This is a Dict mapping parameter indices to a a vector of confidence intervals from each output of q for the corresponding parameter. \nunion_cis: This gives the union of the intervals from parameterwise_cis (just taking the extrema over each interal) at each output of q.\n\nWe also return all_curves, a Dict mapping parameter indices to the vector of q values for each parameter,  and these parameter ranges are given in param_ranges. So, the final output looks like:\n\n(parameterwise_cis, union_cis, all_curves, param_ranges).\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#ProfileLikelihood.eval_prediction_function","page":"Docstrings","title":"ProfileLikelihood.eval_prediction_function","text":"eval_prediction_function(q, prof::ProfileLikelihoodSolution, data;\n    resolution=250,\n    param_ranges=Dict(profiled_parameters(prof) .=> [LinRange(get_confidence_intervals(prof[i])..., resolution) for i in profiled_parameters(prof)]),\n    q_type=get_q_type(q, prof, data))\n\nGiven a prediction of the form q(θ, data), where θ has the same size as the θ used in  the profile likelihood solution prof, and data is the argument data, and for each parameter index i: Evaluates q((ψ, ωˢ(ψ)), data), where ψ ranges over param_ranges[i] and ωˢ(ψ) are the parameter values  that lead to the value of the profile likelihood function where θ[i] = ψ. \n\nYou can set the type of the output from the prediction function q using q_type.\n\nThe output is a Dict mapping the profiled parameter indices (from profiled_parameters) to the outputs from q at each  corresponding parameter in param_ranges.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#Plotting","page":"Docstrings","title":"Plotting","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"plot_profiles ","category":"page"},{"location":"docstrings/#ProfileLikelihood.plot_profiles","page":"Docstrings","title":"ProfileLikelihood.plot_profiles","text":"plot_profiles(prof::ProfileLikelihoodSolution, vars = profiled_parameters(prof); \n    ncol=nothing, \n    nrow=nothing,\n    true_vals=Dict(vars .=> nothing), \n    spline=true, \n    show_mles=true, \n    shade_ci=true, \n    fig_kwargs=nothing, \n    axis_kwargs=nothing,\n    latex_names = Dict(vars .=> [LaTeXStrings.L\"\theta_{i}\" for i in SciMLBase.sym_to_index.(vars, Ref(prof))]))\n\nPlot results from a profile likelihood solution prof.\n\nArguments\n\nprof::ProfileLikelihoodSolution: The profile likelihood solution from profile.\nvars = profiled_parameters(prof): The parameters to plot.\n\nKeyword Arguments\n\nncol=nothing: The number of columns to use. If nothing, chosen automatically via choose_grid_layout.\nnrow=nothing: The number of rows to use. If nothing, chosen automatically via choose_grid_layout\ntrue_vals=Dict(vars .=> nothing): A dictionary mapping parameter indices to their true values, if they exist. If nothing, nothing is plotted, otherwise a black line is plotted at the true value for the profile. \nspline=true: Whether the curve plotted should come from a spline through the results, or if the data itself should be plotted. \nshow_mles=true: Whether to put a red line at the MLEs. \nshade_ci=true: Whether to shade the area under the profile between the confidence interval.\nfig_kwargs=nothing: Extra keyword arguments for Figure (see the Makie docs).\naxis_kwargs=nothing: Extra keyword arguments for Axis (see the Makie docs).\nlatex_names = Dict(vars .=> [LaTeXStrings.L\"\theta_{i}\" for i in SciMLBase.sym_to_index.(vars, Ref(prof))])): LaTeX names to use for the parameters. Defaults to θᵢ, where i is the index of the parameter. \n\nOutput\n\nThe Figure() is returned.\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#GridSearch","page":"Docstrings","title":"GridSearch","text":"","category":"section"},{"location":"docstrings/#Grid-definitions","page":"Docstrings","title":"Grid definitions","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"ProfileLikelihood.AbstractGrid \nProfileLikelihood.RegularGrid \nProfileLikelihood.IrregularGrid ","category":"page"},{"location":"docstrings/#ProfileLikelihood.AbstractGrid","page":"Docstrings","title":"ProfileLikelihood.AbstractGrid","text":"abstract type AbstractGrid{N,B,T}\n\nType representing a grid, where N is the number of parameters, B is the type for the  bounds, and T is the number type.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.RegularGrid","page":"Docstrings","title":"ProfileLikelihood.RegularGrid","text":"struct RegularGrid{N,B,R,S,T} <: AbstractGrid{N,B,T}\n\nStruct for a grid in which each parameter is regularly spaced. \n\nFields\n\nlower_bounds::B: Lower bounds for each parameter. \nupper_bounds::B: Upper bounds for each parameter. \nresolution::R: Number of grid points for each parameter. If R <: Number, then the same number of grid points is used for each parameter. \nstep_sizes::S: Grid spacing for each parameter. \n\nConstructor\n\nYou can construct a RegularGrid using RegularGrid(lower_bounds, upper_bounds, resolution).\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.IrregularGrid","page":"Docstrings","title":"ProfileLikelihood.IrregularGrid","text":"struct IrregularGrid{N,B,R,S,T} <: AbstractGrid{N,B,T}\n\nStruct for an irregular grid of parameters.\n\nFields\n\nlower_bounds::B: Lower bounds for each parameter. \nupper_bounds::B: Upper bounds for each parameter. \ngrid::G: The set of parameter values, e.g. a matrix where each column is the parameter vector.\n\nConstructor\n\nYou can construct a IrregularGrid using IrregularGrid(lower_bounds, upper_bounds, grid).\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#Performing-a-grid-search","page":"Docstrings","title":"Performing a grid search","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"ProfileLikelihood.GridSearch\ngrid_search ","category":"page"},{"location":"docstrings/#ProfileLikelihood.GridSearch","page":"Docstrings","title":"ProfileLikelihood.GridSearch","text":"struct GridSearch{F,G}\n\nStruct for a GridSearch.\n\nFields\n\nf::F: The function to optimise, of the form f(x, p).\np::P: The arguments p in the function f.\ngrid::G: The grid, where G<:AbstractGrid. See also grid_search.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#ProfileLikelihood.grid_search","page":"Docstrings","title":"ProfileLikelihood.grid_search","text":"grid_search(prob; save_vals=Val(false), minimise:=Val(false), parallel=Val(false))\n\nPerforms a grid search for the given grid search problem prob.\n\nArguments\n\nprob::GridSearch{F, G}: The grid search problem.\n\nKeyword Arguments\n\nsave_vals:=Val(false): Whether to return a array with the function values. \nminimise:=Val(false): Whether to minimise or to maximise the function.\nparallel:=Val(false): Whether to run the grid search with multithreading.\n\nOutputs\n\nf_opt: The optimal objective value. \nx_argopt: The parameter that gave f_opt.\nf_res: If save_vals==Val(true), then this is the array of function values.\n\n\n\n\n\ngrid_search(f, grid::AbstractGrid; save_vals=Val(false), minimise=Val(false), parallel=Val(false))\n\nFor a given grid and function f, performs a grid search. \n\nArguments\n\nf: The function to optimise. \ngrid::AbstractGrid: The grid to use for optimising. \n\nKeyword Arguments\n\nsave_vals=Val(false): Whether to return a array with the function values. \nminimise=Val(false): Whether to minimise or to maximise the function.\nparallel=Val(false): Whether to run the grid search with multithreading.\n\n\n\n\n\ngrid_search(prob::LikelihoodProblem, grid::AbstractGrid, parallel=Val(false); save_vals=Val(false))\n\nGiven a grid and a likelihood problem prob, maximises it over the grid using a grid search. If  save_vals==Val(true), then the likelihood function values at each gridpoint are returned. Set  parallel=Val(true) if you want multithreading.\n\n\n\n\n\n","category":"function"}]
}
