<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example IV: Lotka-Volterra ODE and computing bivarate profile likelihoods · ProfileLikelihood.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://DanielVandH.github.io/ProfileLikelihood.jl/lotka/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ProfileLikelihood.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../interface/">Interface</a></li><li><a class="tocitem" href="../docstrings/">Docstrings</a></li><li><a class="tocitem" href="../regression/">Example I: Multiple linear regression</a></li><li><a class="tocitem" href="../logistic/">Example II: Logistic ordinary differential equation</a></li><li><a class="tocitem" href="../exponential/">Example III: Linear exponential ODE and grid searching</a></li><li class="is-active"><a class="tocitem" href>Example IV: Lotka-Volterra ODE and computing bivarate profile likelihoods</a><ul class="internal"><li><a class="tocitem" href="#Data-generation-and-setting-up-the-problem"><span>Data generation and setting up the problem</span></a></li><li><a class="tocitem" href="#Parameter-estimation"><span>Parameter estimation</span></a></li><li><a class="tocitem" href="#Bivariate-profiles"><span>Bivariate profiles</span></a></li><li><a class="tocitem" href="#Prediction-intervals"><span>Prediction intervals</span></a></li></ul></li><li><a class="tocitem" href="../stefan/">Example V: Fisher-Stefan PDE</a></li><li><a class="tocitem" href="../math/">Mathematical and Implementation Details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example IV: Lotka-Volterra ODE and computing bivarate profile likelihoods</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example IV: Lotka-Volterra ODE and computing bivarate profile likelihoods</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/DanielVandH/ProfileLikelihood.jl/blob/main/docs/src/lotka.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Example-IV:-Lotka-Volterra-ODE-and-computing-bivarate-profile-likelihoods"><a class="docs-heading-anchor" href="#Example-IV:-Lotka-Volterra-ODE-and-computing-bivarate-profile-likelihoods">Example IV: Lotka-Volterra ODE and computing bivarate profile likelihoods</a><a id="Example-IV:-Lotka-Volterra-ODE-and-computing-bivarate-profile-likelihoods-1"></a><a class="docs-heading-anchor-permalink" href="#Example-IV:-Lotka-Volterra-ODE-and-computing-bivarate-profile-likelihoods" title="Permalink"></a></h1><p>This example comes from the second case study of <a href="https://doi.org/10.1101/2022.12.14.520367">Simpson and Maclaren (2022)</a>. First, load the packages we&#39;ll be using:</p><pre><code class="language-julia hljs">using Random
using Optimization
using OrdinaryDiffEq
using CairoMakie
using ProfileLikelihood
using OptimizationNLopt
using StableRNGs</code></pre><p>In this example, we will be considering the Lotka-Volterra ODE. We show how bivariate profiles can be computed, along with prediction intervals from a bivariate profile.  The Lotka-Volterra ODE is given by </p><p class="math-container">\[\begin{align*}
\frac{\mathrm da(t)}{\mathrm dt} &amp;= \alpha a(t) - a(t)b(t), \\
\frac{\mathrm db(t)}{\mathrm dt} &amp;= \beta a(t)b(t)-b(t),
\end{align*}\]</p><p>and we suppose that <span>$a(0) = a_0$</span> and <span>$b(0) = b_0$</span>. For this problem, we are interested in estimating <span>$\boldsymbol = (\alpha,\beta,a_0,b_0)$</span>. We suppose that we have measures of the prey and predicator populations, given respectively by <span>$a(t)$</span> and <span>$b(t)$</span>, at times <span>$t_i$</span>, <span>$i=1,\ldots,m$</span>. Letting <span>$a_i^ o = a(t_i)$</span> and <span>$b_i^o = b(t_i)$</span>, <span>$i=1,\ldots,m$</span>, this means that we have the time series <span>$\{(a_i^o, b_i^o)\}_{i=1}^m$</span>. Moreover, just as we did in the logistic ODE example, we suppose that the data <span>$(a_i^o, b_i^o)$</span> are normally distributed about the solution curve <span>$\boldsymbol z(t; \boldsymbol\theta) = (a(t; \boldsymbol \theta), b(t; \boldsymbol \theta))$</span>. In particular, letting <span>$\boldsymbol z_i(\boldsymbol \theta)$</span> denote the value of <span>$(a(t_i; \boldsymbol\theta), b(t_i; \boldsymbol \theta))$</span> at <span>$t=t_i$</span>, we are supposing that </p><p class="math-container">\[(a_i^o, b_i^o) \sim \mathcal N\left(\boldsymbol z_i(\boldsymbol \theta), \sigma^2 \boldsymbol I\right), \quad i=1,2,\ldots,m,\]</p><p>and this is what defines our likelihood (<span>$\boldsymbol I$</span> is the <span>$2$</span>-square identity matrix). We use values <span>$0 \leq t \leq 7$</span> for estimation, and predict on <span>$0 \leq t \leq 10$</span>.</p><h2 id="Data-generation-and-setting-up-the-problem"><a class="docs-heading-anchor" href="#Data-generation-and-setting-up-the-problem">Data generation and setting up the problem</a><a id="Data-generation-and-setting-up-the-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Data-generation-and-setting-up-the-problem" title="Permalink"></a></h2><p>As usual, the first step in this example is generating the data.</p><pre><code class="language-julia hljs">using OrdinaryDiffEq, Random, StableRNGs

## Step 1: Generate the data and define the likelihood
α = 0.9
β = 1.1
a₀ = 0.8
b₀ = 0.3
σ = 0.2
t = LinRange(0, 10, 21)
@inline function ode_fnc!(du, u, p, t) 
    α, β = p
    a, b = u
    du[1] = α * a - a * b
    du[2] = β * a * b - b
    return nothing
end
# Initial data is obtained by solving the ODE 
tspan = extrema(t)
p = [α, β]
u₀ = [a₀, b₀]
prob = ODEProblem(ode_fnc!, u₀, tspan, p)
sol = solve(prob, Rosenbrock23(), saveat=t)
rng = StableRNG(2828881)
noise_vec = [σ * randn(rng, 2) for _ in eachindex(t)]
uᵒ = sol.u .+ noise_vec</code></pre><p>We now define the likelihood function. </p><pre><code class="language-julia hljs">function loglik_fnc2(θ::AbstractVector{T}, data, integrator) where {T}
    α, β, a₀, b₀ = θ
    uᵒ, σ, u₀, n = data
    integrator.p[1] = α
    integrator.p[2] = β
    u₀[1] = a₀
    u₀[2] = b₀
    reinit!(integrator, u₀)
    solve!(integrator)
    ℓ = zero(T)
    for i in 1:n
        âᵒ = integrator.sol.u[i][1]
        b̂ᵒ = integrator.sol.u[i][2]
        aᵒ = uᵒ[i][1]
        bᵒ = uᵒ[i][2]
        ℓ = ℓ - 0.5log(2π * σ^2) - 0.5(âᵒ - aᵒ)^2 / σ^2
        ℓ = ℓ - 0.5log(2π * σ^2) - 0.5(b̂ᵒ - bᵒ)^2 / σ^2
    end
    return ℓ
end</code></pre><p>Now we define our problem, constraining the parameters so that <span>$0.7 \leq \alpha \leq 1.2$</span>, <span>$0.7 \leq \beta \leq 1.4$</span>, <span>$0.5 \leq a_0 \leq 1.2$</span>, and <span>$0.1 \leq b_0 \leq 0.5$</span>. </p><pre><code class="language-julia hljs">using Optimization, OrdinaryDiffEq, ProfileLikelihood
lb = [0.7, 0.7, 0.5, 0.1]
ub = [1.2, 1.4, 1.2, 0.5]
θ₀ = [0.75, 1.23, 0.76, 0.292]
syms = [:α, :β, :a₀, :b₀]
u₀_cache = zeros(2)
n = findlast(t .≤ 7) # Using t ≤ 7 for estimation
prob = LikelihoodProblem(
    loglik_fnc2, θ₀, ode_fnc!, u₀, tspan;
    syms=syms,
    data=(uᵒ, σ, u₀_cache, n),
    ode_parameters=[1.0, 1.0],
    ode_kwargs=(verbose=false, saveat=t),
    prob_kwargs = (lb=lb, ub=ub),
    ode_alg=Rosenbrock23()
)</code></pre><pre><code class="language-julia hljs">LikelihoodProblem. In-place: true
θ₀: 4-element Vector{Float64}
     α: 0.75
     β: 1.23
     a₀: 0.76
     b₀: 0.292</code></pre><h2 id="Parameter-estimation"><a class="docs-heading-anchor" href="#Parameter-estimation">Parameter estimation</a><a id="Parameter-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-estimation" title="Permalink"></a></h2><p>Let us now proceed as usual, computing the MLEs and obtaining the profiles. </p><pre><code class="language-julia-repl hljs">julia&gt; using OptimizationNLopt
julia&gt; @time sol = mle(prob, NLopt.LN_NELDERMEAD)
  0.022843 seconds (266.05 k allocations: 10.547 MiB)
LikelihoodSolution. retcode: Success
Maximum likelihood: 7.083346779938254
Maximum likelihood estimates: 4-element Vector{Float64}
     α: 0.8798816617243157
     β: 1.123199229773868
     a₀: 0.860737893924461
     b₀: 0.3320559683543075</code></pre><pre><code class="language-julia hljs">julia&gt; @time prof = profile(prob, sol; parallel=true)
  9.348295 seconds (96.71 M allocations: 3.830 GiB, 3.52% gc time)
ProfileLikelihoodSolution. MLE retcode: Success
Confidence intervals:
     95.0% CI for α: (0.7655588053712551, 0.9947597721255612)
     95.0% CI for β: (1.014685357334102, 1.2569672111855281)
     95.0% CI for a₀: (0.7315323205415538, 0.9964615701946258)
     95.0% CI for b₀: (0.24194969128552055, 0.43338299417186515)</code></pre><p>Now plotting the profiles:</p><pre><code class="language-julia hljs">using CairoMakie
fig = plot_profiles(prof;
    latex_names=[L&quot;\alpha&quot;, L&quot;\beta&quot;, L&quot;a_0&quot;, L&quot;b_0&quot;],
    show_mles=true,
    shade_ci=true,
    nrow=2,
    ncol=2,
    true_vals=[α, β, a₀, b₀])</code></pre><figure>
    <img src='../figures/lokta_example_profiles.png', alt'Lotka profiles'><br>
</figure><h2 id="Bivariate-profiles"><a class="docs-heading-anchor" href="#Bivariate-profiles">Bivariate profiles</a><a id="Bivariate-profiles-1"></a><a class="docs-heading-anchor-permalink" href="#Bivariate-profiles" title="Permalink"></a></h2><p>In all the examples thus far, we have only considered univariate profiles. We also provide a method for computing bivariate profiles through the <code>bivariate_profile</code> function. In this function instead of providing a set of integers for the parameters to profile, we provide tuples of integers (or symbols). Let&#39;s compute the bivariate profiles for all pairs. In the code below, <code>resolution=25</code> means we define 25 layers between the MLE and the bounds for each parameter (see the implementation details section in the sidebar for a definition of a layer). Setting <code>outer_layers=10</code> means that we go out 10 layers even after finding the complete confidence region.</p><pre><code class="language-julia hljs">param_pairs = ((:α, :β), (:α, :a₀), (:α, :b₀),
    (:β, :a₀), (:β, :b₀),
    (:a₀, :b₀)) # Same as param_pairs = ((1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4))
@time prof_2 = bivariate_profile(prob, sol, param_pairs; parallel=true, resolution=25, outer_layers=10) 
# Multithreading highly recommended for bivariate profiles - even a resolution of 25 is an upper bound of 2,601 optimisation problems for each pair (in general, this number is 4N(N+1) + 1 for a resolution of N).</code></pre><pre><code class="language-julia hljs">255.794233 seconds (1.15 G allocations: 45.774 GiB, 2.00% gc time, 2.20% compilation time)
BivariateProfileLikelihoodSolution. MLE retcode: Success
Profile info:
     (β, b₀): 25 layers. Bbox for 95.0% CR: [0.9910523784900991, 1.29477713384572] × [0.21992309825215978, 0.45954937571653703]
     (α, β): 25 layers. Bbox for 95.0% CR: [0.7357005284921787, 1.0221575680079797] × [0.991123194005582, 1.2949721520687736]
     (α, a₀): 25 layers. Bbox for 95.0% CR: [0.7357619449614752, 1.0219994350896653] × [0.702688464342064, 1.0333477627025405]
     (a₀, b₀): 25 layers. Bbox for 95.0% CR: [0.7026997627224284, 1.0333698932787927] × [0.21999696665137455, 0.459589626124184]
     (α, b₀): 25 layers. Bbox for 95.0% CR: [0.7357403217306449, 1.0221076705696055] × [0.21999378985874352, 0.45959053842574044]
     (β, a₀): 25 layers. Bbox for 95.0% CR: [0.9912086964720968, 1.2949252238744442] × [0.7026534659606257, 1.0329841074487238]</code></pre><p>To plot these profiles, we can use <code>plot_profiles</code>. These plots usually take a bit more work than the univariate case. Let&#39;s first show a poor plot. We specify <code>xlims</code> and <code>ylims</code> to match <a href="https://doi.org/10.1101/2022.12.14.520367">Simpson and Maclaren (2022)</a>.</p><pre><code class="language-julia hljs">fig_2 = plot_profiles(prof_2, param_pairs; # param_pairs not needed, but this ensures we get the correct order
    latex_names=[L&quot;\alpha&quot;, L&quot;\beta&quot;, L&quot;a_0&quot;, L&quot;b_0&quot;],
    show_mles=true,
    nrow=3,
    ncol=2,
    true_vals=[α, β, a₀, b₀],
    xlim_tuples=[(0.5, 1.5), (0.5, 1.5), (0.5, 1.5), (0.7, 1.3), (0.7, 1.3), (0.5, 1.1)],
    ylim_tuples=[(0.5, 1.5), (0.5, 1.05), (0.1, 0.5), (0.5, 1.05), (0.1, 0.5), (0.1, 0.5)],
    fig_kwargs=(fontsize=24,))</code></pre><figure>
    <img src='../figures/lokta_example_bivariate_profiles_low_quality.png', alt'Poor Lotka bivariate profiles'><br>
</figure><p>In these plots, the red boundaries mark the confidence region&#39;s boundary, the red dot shows the MLE, and the black dots are the true values. There are two issues with these plots:</p><ol><li>The plots are quite pixelated due to the low resolution.</li><li>The plots don&#39;t fill out the entire axis.</li></ol><p>These two issues can be resolved using the interpolant defined from the original data. Setting <code>interpolant = true</code> resolves these two problems. (If we also had a poor quality confidence region, you could also set <code>smooth_confidence_boundary = true</code>.)</p><pre><code class="language-julia hljs">fig_3 = plot_profiles(prof_2, param_pairs;
    latex_names=[L&quot;\alpha&quot;, L&quot;\beta&quot;, L&quot;a_0&quot;, L&quot;b_0&quot;],
    show_mles=true,
    nrow=3,
    ncol=2,
    true_vals=[α, β, a₀, b₀],
    interpolation=true,
    xlim_tuples=[(0.5, 1.5), (0.5, 1.5), (0.5, 1.5), (0.7, 1.3), (0.7, 1.3), (0.5, 1.1)],
    ylim_tuples=[(0.5, 1.5), (0.5, 1.05), (0.1, 0.5), (0.5, 1.05), (0.1, 0.5), (0.1, 0.5)],
    fig_kwargs=(fontsize=24,))</code></pre><figure>
    <img src='../figures/lokta_example_bivariate_profiles_smoothed_quality.png', alt'Smooth Lotka bivariate profiles'><br>
</figure><h2 id="Prediction-intervals"><a class="docs-heading-anchor" href="#Prediction-intervals">Prediction intervals</a><a id="Prediction-intervals-1"></a><a class="docs-heading-anchor-permalink" href="#Prediction-intervals" title="Permalink"></a></h2><p>Let&#39;s now proceed with finding prediction intervals. We first find the prediction intervals using our univariate results. We use the in-place version of a prediction function:</p><pre><code class="language-julia hljs">function prediction_function!(q, θ::AbstractVector{T}, data) where {T}
    α, β, a₀, b₀ = θ
    t, a_idx, b_idx = data
    prob = ODEProblem(ODEFunction(ode_fnc!, syms=(:a, :b)), [a₀, b₀], extrema(t), (α, β))
    sol = solve(prob, Rosenbrock23(), saveat=t)
    q[a_idx] .= sol[:a]
    q[b_idx] .= sol[:b]
    return nothing
end
t_many_pts = LinRange(extrema(t)..., 1000)
a_idx = 1:1000
b_idx = 1001:2000
pred_data = (t_many_pts, a_idx, b_idx)
q_prototype = zeros(2000)
individual_intervals, union_intervals, q_vals, param_ranges =
    get_prediction_intervals(prediction_function!, prof, pred_data; parallel=true,
        q_prototype)</code></pre><p>Now we plot these results, plotting the individual intervals as well as the union intervals. As in Example II, we also look at the intervals from the full likelihood.</p><pre><code class="language-julia hljs"># Evaluate the exact and MLE solutions
exact_soln = zeros(2000)
mle_soln = zeros(2000)
prediction_function!(exact_soln, [α, β, a₀, b₀], pred_data)
prediction_function!(mle_soln, get_mle(sol), pred_data)

# Plot the parameter-wise intervals 
fig = Figure(fontsize=38, resolution=(2935.488f0, 1392.64404f0))
alp = [[&#39;a&#39;, &#39;b&#39;, &#39;e&#39;, &#39;f&#39;], [&#39;c&#39;, &#39;d&#39;, &#39;g&#39;, &#39;h&#39;]]
latex_names = [L&quot;\alpha&quot;, L&quot;\beta&quot;, L&quot;a_0&quot;, L&quot;b_0&quot;]
for (k, idx) in enumerate((a_idx, b_idx))
    for i in 1:4
        ax = Axis(fig[i &lt; 3 ? 1 : 2, mod1(i, 2)+(k==2)*2], title=L&quot;(%$(alp[k][i])): Profile-wise PI for %$(latex_names[i])&quot;,
            titlealign=:left, width=600, height=300, xlabel=L&quot;t&quot;, ylabel=k == 1 ? L&quot;a(t)&quot; : L&quot;b(t)&quot;)
        vlines!(ax, [7.0], color=:purple, linestyle=:dash, linewidth=2)
        lines!(ax, t_many_pts, exact_soln[idx], color=:red, linewidth=3)
        lines!(ax, t_many_pts, mle_soln[idx], color=:blue, linestyle=:dash, linewidth=3)
        lines!(ax, t_many_pts, getindex.(individual_intervals[i], 1)[idx], color=:black, linewidth=3)
        lines!(ax, t_many_pts, getindex.(individual_intervals[i], 2)[idx], color=:black, linewidth=3)
        band!(ax, t_many_pts, getindex.(individual_intervals[i], 1)[idx], getindex.(individual_intervals[i], 2)[idx], color=(:grey, 0.35))
    end
end

# Plot the union intervals
a_ax = Axis(fig[3, 1:2], title=L&quot;(i):$ $ Union of all intervals&quot;,
    titlealign=:left, width=1200, height=300, xlabel=L&quot;t&quot;, ylabel=L&quot;a(t)&quot;)
b_ax = Axis(fig[3, 3:4], title=L&quot;(j):$ $ Union of all intervals&quot;,
    titlealign=:left, width=1200, height=300, xlabel=L&quot;t&quot;, ylabel=L&quot;b(t)&quot;)
_ax = (a_ax, b_ax)
for (k, idx) in enumerate((a_idx, b_idx))
    band!(_ax[k], t_many_pts, getindex.(union_intervals, 1)[idx], getindex.(union_intervals, 2)[idx], color=(:grey, 0.35))
    lines!(_ax[k], t_many_pts, getindex.(union_intervals, 1)[idx], color=:black, linewidth=3)
    lines!(_ax[k], t_many_pts, getindex.(union_intervals, 2)[idx], color=:black, linewidth=3)
    lines!(_ax[k], t_many_pts, exact_soln[idx], color=:red, linewidth=3)
    lines!(_ax[k], t_many_pts, mle_soln[idx], color=:blue, linestyle=:dash, linewidth=3)
    vlines!(_ax[k], [7.0], color=:purple, linestyle=:dash, linewidth=2)
end

# Compare to the results obtained from the full likelihood
lb = get_lower_bounds(prob)
ub = get_upper_bounds(prob)
N = 1e5
grid = [[lb[i] + (ub[i] - lb[i]) * rand() for _ in 1:N] for i in 1:4]
grid = permutedims(reduce(hcat, grid), (2, 1))
ig = IrregularGrid(lb, ub, grid)
gs, lik_vals = grid_search(prob, ig; parallel=Val(true), save_vals=Val(true))
lik_vals .-= get_maximum(sol) # normalised 
feasible_idx = findall(lik_vals .&gt; ProfileLikelihood.get_chisq_threshold(0.95)) # values in the confidence region 
parameter_evals = grid[:, feasible_idx]
full_q_vals = zeros(2000, size(parameter_evals, 2))
@views [prediction_function!(full_q_vals[:, j], parameter_evals[:, j], pred_data) for j in axes(parameter_evals, 2)]
q_lwr = minimum(full_q_vals; dims=2) |&gt; vec
q_upr = maximum(full_q_vals; dims=2) |&gt; vec
for (k, idx) in enumerate((a_idx, b_idx))
    lines!(_ax[k], t_many_pts, q_lwr[idx], color=:magenta, linewidth=3)
    lines!(_ax[k], t_many_pts, q_upr[idx], color=:magenta, linewidth=3)
end</code></pre><figure>
    <img src='../figures/lokta_example_univariate_predictions.png', alt'Lotka univariate predictions'><br>
</figure><p>We see that the uncertainty around our predictions increases significantly for <span>$t &gt; 7$</span>, as expected since we only use data in <span>$0 \leq t \leq 7$</span> for estmiating the parameters. Moreover, the union intervals are good approximations to the intervals from the full likelihood.</p><p>Now let us extend these results, instead computing prediction intervals from our bivariate profiles. The exact same function can be used for this.</p><pre><code class="language-julia hljs"># Bivariate prediction intervals 
individual_intervals, union_intervals, q_vals, param_ranges =
    get_prediction_intervals(prediction_function!, prof_2, pred_data; parallel=true,
        q_prototype)

# Plot the intervals 
fig = Figure(fontsize=38, resolution=(2935.488f0, 1854.64404f0))
integer_param_pairs = ProfileLikelihood.convert_symbol_tuples(param_pairs, prof_2) # converts to the integer representation
alp = [[&#39;a&#39;, &#39;b&#39;, &#39;e&#39;, &#39;f&#39;, &#39;i&#39;, &#39;j&#39;], [&#39;c&#39;, &#39;d&#39;, &#39;g&#39;, &#39;h&#39;, &#39;k&#39;, &#39;l&#39;]]
for (k, idx) in enumerate((a_idx, b_idx))
    for (i, (u, v)) in enumerate(integer_param_pairs)
        ax = Axis(fig[i &lt; 3 ? 1 : (i &lt; 5 ? 2 : 3), mod1(i, 2)+(k==2)*2], title=L&quot;(%$(alp[k][i])): Profile-wise PI for (%$(latex_names[u]), %$(latex_names[v]))&quot;,
            titlealign=:left, width=600, height=300, xlabel=L&quot;t&quot;, ylabel=k == 1 ? L&quot;a(t)&quot; : L&quot;b(t)&quot;)
        vlines!(ax, [7.0], color=:purple, linestyle=:dash, linewidth=2)
        lines!(ax, t_many_pts, exact_soln[idx], color=:red, linewidth=3)
        lines!(ax, t_many_pts, mle_soln[idx], color=:blue, linestyle=:dash, linewidth=3)
        lines!(ax, t_many_pts, getindex.(individual_intervals[(u, v)], 1)[idx], color=:black, linewidth=3)
        lines!(ax, t_many_pts, getindex.(individual_intervals[(u, v)], 2)[idx], color=:black, linewidth=3)
        band!(ax, t_many_pts, getindex.(individual_intervals[(u, v)], 1)[idx], getindex.(individual_intervals[(u, v)], 2)[idx], color=(:grey, 0.35))
    end
end
a_ax = Axis(fig[4, 1:2], title=L&quot;(i):$ $ Union of all intervals&quot;,
    titlealign=:left, width=1200, height=300, xlabel=L&quot;t&quot;, ylabel=L&quot;a(t)&quot;)
b_ax = Axis(fig[4, 3:4], title=L&quot;(j):$ $ Union of all intervals&quot;,
    titlealign=:left, width=1200, height=300, xlabel=L&quot;t&quot;, ylabel=L&quot;b(t)&quot;)
_ax = (a_ax, b_ax)
for (k, idx) in enumerate((a_idx, b_idx))
    band!(_ax[k], t_many_pts, getindex.(union_intervals, 1)[idx], getindex.(union_intervals, 2)[idx], color=(:grey, 0.35))
    lines!(_ax[k], t_many_pts, getindex.(union_intervals, 1)[idx], color=:black, linewidth=3)
    lines!(_ax[k], t_many_pts, getindex.(union_intervals, 2)[idx], color=:black, linewidth=3)
    lines!(_ax[k], t_many_pts, exact_soln[idx], color=:red, linewidth=3)
    lines!(_ax[k], t_many_pts, mle_soln[idx], color=:blue, linestyle=:dash, linewidth=3)
    vlines!(_ax[k], [7.0], color=:purple, linestyle=:dash, linewidth=2)
end
for (k, idx) in enumerate((a_idx, b_idx))
    lines!(_ax[k], t_many_pts, q_lwr[idx], color=:magenta, linewidth=3)
    lines!(_ax[k], t_many_pts, q_upr[idx], color=:magenta, linewidth=3)
end</code></pre><figure>
    <img src='../figures/lokta_example_bivariate_predictions.png', alt'Lotka bivarate predictions'><br>
</figure></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../exponential/">« Example III: Linear exponential ODE and grid searching</a><a class="docs-footer-nextpage" href="../stefan/">Example V: Fisher-Stefan PDE »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 4 August 2023 01:52">Friday 4 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
