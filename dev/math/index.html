<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Mathematical and Implementation Details · ProfileLikelihood.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ProfileLikelihood.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../interface/">Interface</a></li><li><a class="tocitem" href="../docstrings/">Docstrings</a></li><li><a class="tocitem" href="../regression/">Example I: Multiple linear regression</a></li><li><a class="tocitem" href="../logistic/">Example II: Logistic ordinary differential equation</a></li><li><a class="tocitem" href="../exponential/">Example III: Linear exponential ODE and grid searching</a></li><li><a class="tocitem" href="../heat/">Example IV: Diffusion equation on a square plate</a></li><li class="is-active"><a class="tocitem" href>Mathematical and Implementation Details</a><ul class="internal"><li><a class="tocitem" href="#Computing-the-profile-likelihood-function"><span>Computing the profile likelihood function</span></a></li><li><a class="tocitem" href="#Computing-prediction-intervals"><span>Computing prediction intervals</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Mathematical and Implementation Details</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Mathematical and Implementation Details</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/DanielVandH/ProfileLikelihood.jl/blob/main/docs/src/math.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Mathematical-and-Implementation-Details"><a class="docs-heading-anchor" href="#Mathematical-and-Implementation-Details">Mathematical and Implementation Details</a><a id="Mathematical-and-Implementation-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-and-Implementation-Details" title="Permalink"></a></h1><p>We now give some of the mathematical and implementation details used in this package, namely for computing the profile likelihood function and for computing prediction intervals.</p><h2 id="Computing-the-profile-likelihood-function"><a class="docs-heading-anchor" href="#Computing-the-profile-likelihood-function">Computing the profile likelihood function</a><a id="Computing-the-profile-likelihood-function-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-the-profile-likelihood-function" title="Permalink"></a></h2><p>Let us start by giving a mathematical description of the method that we use for computing the profile log-likelihood function. Suppose that we have a parameter vector <span>$\boldsymbol\theta$</span> that we partition as <span>$\boldsymbol \theta = (\psi, \boldsymbol \omega)$</span> (<span>$\psi$</span> is a scalar in this description, since we only support univariate profiles currently). We suppose that we have a likelihood function <span>$\mathcal L(\boldsymbol \theta) \equiv \mathcal L(\psi, \boldsymbol \omega)$</span> so that the normalised profile log-likelihood function for <span>$\psi$</span> is defined as </p><p class="math-container">\[\hat\ell_p(\psi) = \sup_{\boldsymbol \omega \in \Omega \mid \psi} \left[\ell(\psi, \boldsymbol\omega) - \ell^*\right],\]</p><p>where <span>$\Omega$</span> is the parameter space for <span>$\boldsymbol \omega$</span>, <span>$\ell(\psi,\boldsymbol\omega) = \log \mathcal L(\psi, \boldsymbol \omega)$</span>, and <span>$\ell^* = \ell(\hat{\boldsymbol \theta})$</span>, where <span>$\boldsymbol \theta$</span> are the MLEs for <span>$\boldsymbol \theta$</span>. This definition of <span>$\hat\ell_p(\psi)$</span> induces a function <span>$\boldsymbol\omega^*(\psi)$</span> depending on <span>$\psi$</span> that gives the values of <span>$\boldsymbol \omega$</span> leading to the supremum above, i.e. </p><p class="math-container">\[\ell(\psi, \boldsymbol\omega^{\star}(\psi)) = \sup_{\boldsymbol \omega \in \Omega \mid \psi} \left[\ell(\psi, \boldsymbol\omega) - \ell^{\star}\right]. \]</p><p>To compute <span>$\hat\ell_p(\psi)$</span>, then, requires a way to efficiently compute the <span>$\omega^*(\psi)$</span>, and requires knowing where to stop computing. Where we stop computing the profile likelihood is simply when <span>$\hat\ell_p(\psi) &lt; -\chi_{1,1-\alpha}^2/2$</span>, where <span>$\alpha$</span> is the significance level (e.g. <span>$\alpha=0.05$</span>, in which case <span>$\chi_{1,1-0.05}^2/2 \approx 1.92$</span>). This motivates a iterative algorithm, where we start at the MLE and then step left and right.</p><p>We describe how we evaluate the function to the right of the MLE – the case of going to the left is identical. First, we define <span>$\psi_1 = \hat\psi$</span>, where <span>$\hat\psi$</span> is the MLE for <span>$\psi$</span>. This defines <span>$\boldsymbol{\omega}\_{1} = \boldsymbol{\omega}^{\star}(\psi\_{1})$</span>, which in this case just gives the MLE <span>$\hat{\boldsymbol\theta} = (\hat\psi, \boldsymbol\omega_1)$</span> by definition. The value of the normalised profile log-likelihood here is simply <span>$\hat\ell_1 = \hat\ell(\psi_1) = 0$</span>. Then, defining some step size <span>$\Delta\psi$</span>, we define <span>$\psi_2 = \psi_1 + \Delta \psi$</span>, and in general <span>$\psi_{j+1} = \psi_j + \Delta \psi$</span>, we need to estimate <span>$\boldsymbol\omega_2 = \boldsymbol \omega^*(\psi\_2)$</span>. We do this by starting an optimiser at the initial estimate <span>$\boldsymbol\omega_2 = \boldsymbol\omega_1$</span> and then using this initial estimate to produce a refined value of <span>$\boldsymbol\omega_2$</span> that we take as its true value. In particular, each <span>$\boldsymbol\omega_j$</span> comes from starting the optimiser at the previous <span>$\boldsymbol\omega_{j-1}$</span>, and the value for <span>$\hat\ell_j = \hat\ell(\psi_j)$</span> comes from the value of the likelihood at <span>$(\psi_j, \boldsymbol\omega_j)$</span>. The same holds when going to the left except with <span>$\psi_{j+1} = \psi_j - \Delta\psi$</span>, and then rearranging the indices <span>$j$</span> when combining the results to the left and to the right.  At each step, we check if <span>$\hat\ell_j &lt; -\chi_{1,1-\alpha}^2/2$</span> and, if so, we terminate. </p><p>Once we have terminated the algorithm, we need to obtain the confidence intervals. To do this, we fit a spline to the data <span>$(\psi_j, \hat\ell_j)$</span>, and use a bisection algorithm over the two intervals <span>$(\min_j \psi_j, \hat\psi)$</span> and <span>$(\hat\psi, \max_j\psi_j)$</span>, to find where <span>$\hat\ell_j = -\chi_{1-\alpha}^2/2$</span>. This leads to two solutions <span>$(L, U)$</span> that we take together to give the confidence interval for <span>$\psi$</span>. </p><p>This is all done for each parameter.</p><p>Note that a better method for initialising the optimisation for <span>$\boldsymbol\omega_j$</span> may be to use e.g. linear interpolation for the previous two values, <span>$\boldsymbol\omega_{j-1}$</span> and <span>$\boldsymbol\omega_{j-2}$</span> (with special care for the bounds of the parameters). We provide support for this, letting <span>$\boldsymbol\omega_j = [\boldsymbol\omega_{j-2}(\psi_{j-1} - \psi_j) + \boldsymbol\omega_{j-1}(\psi_j - \psi_{j-2})] / (\psi_{j-1} - \psi_{j-2})$</span>. See the <code>next_initial_estimate_method</code> option in <code>?profile</code>.</p><h2 id="Computing-prediction-intervals"><a class="docs-heading-anchor" href="#Computing-prediction-intervals">Computing prediction intervals</a><a id="Computing-prediction-intervals-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-prediction-intervals" title="Permalink"></a></h2><p>Our method for computing prediction intervals follows <a href="https://doi.org/10.1101/2022.12.14.520367">Simpson and Maclaren (2022)</a>, as does our description that follows. This method is nice as it provides a means for sensitivity analysis, enabling the attribution of components of uncertainty in some prediction function <span>$q(\psi, \boldsymbol \omega)$</span> (with <span>$\psi$</span> the interest parameter and <span>$\boldsymbol\omega$</span> the nuisance parameters as above) to individual parameters. The resulting intervals are called <em>profile-wise intervals</em>, with the predictions themselves called <em>parameter-based, profile-wise predictions</em> or <em>profile-wise predictions</em>.</p><p>The idea is to take a set of profile likelihoods and the confidence intervals obtained from each, and then pushing those into a prediction function that we then use to obtain prediction intervals, making heavy use of the transformation invariance property of MLEs.</p><p>So, let us start with some prediction function <span>$q(\psi, \boldsymbol \omega)$</span>, and recall that the profile likelihood function for <span>$\psi$</span> induces a function <span>$\boldsymbol\omega^{\star}(\psi)$</span>. The profile-wise likelihood for <span>$q$</span>, given the set of values <span>$(\psi, \boldsymbol\omega^{\star}(\psi))$</span>, is defined by </p><p class="math-container">\[\hat\ell_p\left(q\left(\psi, \boldsymbol\omega^{\star}(\psi)\right) = q\right) = \sup_{\psi \mid  q\left(\psi, \boldsymbol\omega^{\star}(\psi)\right) = q} \hat\ell_p(\psi). \]</p><p>Note that if <span>$q(\psi, \boldsymbol\omega^{\star}(\psi))$</span> is injective, there is only one such <span>$\psi$</span> such that <span>$q\left(\psi, \boldsymbol\omega^{\star}(\psi)\right) = q&#39;$</span> for any given <span>$q&#39;$</span> in which case the profile-wise likelihood for <span>$q$</span> (based on <span>$\psi$</span>) is simply <span>$\hat\ell_p(\psi)$</span>. This definition is intuitive, recalling that the profile likelihood comes from a definition like the above except with the likelihood function on the right, so profile-wise likelihoods come from profile likelihoods.  Using this definition, and using the transformation invariance property of the MLE, confidence sets for <span>$\psi$</span> directly translate into confidence sets for <span>$q$</span>, in particular to find a <span>$100(1-\alpha)\%$</span> prediction interval for <span>$q$</span> we need only evaluate <span>$q$</span> for <span>$\psi$</span> inside its confidence interval.</p><p>Let us now describe the extra details involved in obtaining these prediction intervals, in particular what we are doing in the <code>get_prediction_intervals</code> function. For this, we imagine that <span>$q$</span> is scalar valued, but the description below can be easily extended to the vector case (just apply the idea to each component – see the logistic ODE example). We also only explain this for a single parameter <span>$\psi$</span>, but we describe how we use the results for each parameter to obtain a more conservative interval.</p><p>The first step is to evaluate the family of curves. If we suppose that the confidence interval for <span>$\psi$</span> is <span>$(\psi_L, \psi_U)$</span>, we define <span>$\psi_j = \psi_L + (j-1)(\psi_U - \psi_L)/(n_\psi - 1)$</span>, <span>$j=1,\ldots,n_\psi$</span> – this is a set of <span>$n_\psi$</span> equally spaced points between the interval limits. For each <span>$\psi_j$</span> we need to then compute <span>$\boldsymbol\omega^{\star}(\psi_j)$</span>. Rather than re-optimise, we use the data from our profile likelihoods, where we have stored values for <span>$(\psi, \boldsymbol\omega^{\star}(\psi))$</span> to define a continuous function <span>$\boldsymbol\omega^{\star}(\psi)$</span> via linear interpolation. Using this linear interpolant we can thus compute <span>$\boldsymbol\omega^{\star}(\psi_j)$</span> for each gridpoint <span>$\psi_j$</span>. We can therefore compute <span>$\boldsymbol\theta_j = (\psi_j, \boldsymbol\omega^{\star}(\psi_j))$</span> so that we can evaluate the prediction function at each <span>$\psi_j$</span>, <span>$q_j = q(\boldsymbol\theta_j)$</span>. </p><p>We now have a sample <span>${q_1, \ldots, q_{n_\psi}}$</span>. If we let <span>$q_L = min_{j=1}^{n_\psi} q_j$</span> and <span>$q_U = max_{j=1}^{n_\psi} q_j$</span>, then our prediction interval is <span>$(q_L, q_U)$</span>. To be more specific, this is the profile-wise interval for <span>$q$</span> given the basis <span>$(\psi, \boldsymbol\omega^{\star}(\psi))$</span>.</p><p>We have now described how prediction intervals are obtained based on a single parameter. Suppose we do this for a collection of parameters <span>$\{\psi^1, \ldots, \psi^d\}$</span> (e.g. if <span>$\boldsymbol\theta = (D, \lambda, K)$</span>, then we might have computed profiles for <span>$\psi^1=D$</span>, <span>$\psi^2=\lambda$</span>, and <span>$\psi^3=K$</span>), giving <span>$d$</span> different intervals for each <span>$\psi^i$</span>, say <span>${(q_L^i, q_U^i)}\_{i=1}^d$</span>. We can take the union of these intervals to get a more conservative interval for the prediction, giving the new interval <span>$(min_{i=1}^d q_L^i, max_{i=1}^d q_U^i)$</span>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../heat/">« Example IV: Diffusion equation on a square plate</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 23 December 2022 07:05">Friday 23 December 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
